D:\Xzh\John计算机前沿课程\Group_Project\torchdiffeq\fooling\ode_fooling.py
D:\Xzh\John计算机前沿课程\Group_Project\torchdiffeq\fooling\ode_fooling2.py
D:\Xzh\John计算机前沿课程\Group_Project\torchdiffeq\fooling\ode_fooling2.py
import argparse
import logging
import os
import time

import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torchvision.utils import save_image

import foolbox
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.gridspec as gridspec

DOWNLOAD_MNIST = False 
use_gray = False       

parser = argparse.ArgumentParser()
parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')
parser.add_argument('--tol', type=float, default=1e-3)
parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])
parser.add_argument('--downsampling-method', type=str, default='res', choices=['conv', 'res'])
parser.add_argument('--nepochs', type=int, default=160)
parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])
parser.add_argument('--lr', type=float, default=0.1)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--continuing', type=eval, default=False, choices=[True, False])
parser.add_argument('--save', type=str, default='./experiment1')
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint


def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)


def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


def norm(dim):
    return nn.GroupNorm(min(32, dim), dim)


def my_show_transform(x, use_gray):
    x = (x + 1.0) / 2.0
    """Imshow for Tensor."""
    x = np.clip(x, 0, 1)
    if use_gray:
        plt.imshow(x, cmap ='gray')
    else:
        plt.imshow(x)
    return x


class ResBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(ResBlock, self).__init__()
        self.norm1 = norm(inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.norm2 = norm(planes)
        self.conv2 = conv3x3(planes, planes)

    def forward(self, x):
        shortcut = x

        out = self.relu(self.norm1(x))

        if self.downsample is not None:
            shortcut = self.downsample(out)

        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)

        return out + shortcut


class ODEfunc(nn.Module):

    def __init__(self, dim):
        super(ODEfunc, self).__init__()
        self.norm1 = norm(dim)
        self.relu = nn.ReLU(inplace=True)
        self.conv1 = conv3x3(dim, dim)
        self.norm2 = norm(dim)
        self.conv2 = conv3x3(dim, dim)
        self.norm3 = norm(dim)
        self.nfe = 0

    def forward(self, t, x):
        self.nfe += 1
        out = self.norm1(x)
        out = self.relu(out)
        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.norm3(out)
        return out


class ODEBlock(nn.Module):

    def __init__(self, odefunc):
        super(ODEBlock, self).__init__()
        self.odefunc = odefunc
        self.integration_time = torch.tensor([0, 1]).float()

    def forward(self, x):
        self.integration_time = self.integration_time.type_as(x)
        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)
        return out[1]

    @property
    def nfe(self):
        return self.odefunc.nfe

    @nfe.setter
    def nfe(self, value):
        self.odefunc.nfe = value


class Flatten(nn.Module):

    def __init__(self):
        super(Flatten, self).__init__()

    def forward(self, x):
        shape = torch.prod(torch.tensor(x.shape[1:])).item()
        return x.view(-1, shape)


class RunningAverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self, momentum=0.99):
        self.momentum = momentum
        self.reset()

    def reset(self):
        self.val = None
        self.avg = 0

    def update(self, val):
        if self.val is None:
            self.avg = val
        else:
            self.avg = self.avg * self.momentum + val * (1 - self.momentum)
        self.val = val


def inf_generator(iterable):
    """Allows training with DataLoaders in a single infinite loop:
        for i, (x, y) in enumerate(inf_generator(train_loader)):
    """
    iterator = iterable.__iter__()
    while True:
        try:
            yield iterator.__next__()
        except StopIteration:
            iterator = iterable.__iter__()


def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):
    initial_learning_rate = args.lr * batch_size / batch_denom

    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]
    vals = [initial_learning_rate * decay for decay in decay_rates]

    def learning_rate_fn(itr):
        lt = [itr < b for b in boundaries] + [True]
        i = np.argmax(lt)
        return vals[i]

    return learning_rate_fn


def one_hot(x, K):
    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)


def accuracy(model, dataset_loader):
    total_correct = 0
    for x, y in dataset_loader:
        x = x.to(device)
        y = one_hot(np.array(y.numpy()), 10)

        target_class = np.argmax(y, axis=1)
        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)
        total_correct += np.sum(predicted_class == target_class)
    return total_correct / len(dataset_loader.dataset)


def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def makedirs(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):
    logger = logging.getLogger()
    if debug:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logger.setLevel(level)
    if saving:
        info_file_handler = logging.FileHandler(logpath, mode="a")
        info_file_handler.setLevel(level)
        logger.addHandler(info_file_handler)
    if displaying:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        logger.addHandler(console_handler)
    logger.info(filepath)
    with open(filepath, "r") as f:
        logger.info(f.read())

    for f in package_files:
        logger.info(f)
        with open(f, "r") as package_f:
            logger.info(package_f.read())

    return logger


if __name__ == '__main__':

    makedirs(args.save)
    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)

    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')

    is_odenet = args.network == 'odenet'

    if args.downsampling_method == 'conv':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
        ]
    elif args.downsampling_method == 'res':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
        ]

    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]
    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]

    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)
    
    # pay attention to this!! 
    SET_CONTINUE = True
    if args.continuing or SET_CONTINUE:
        model.load_state_dict(torch.load('model.pth')['state_dict'])

    mean = np.array([0.5])
    std = np.array([0.5])

    fmodel = foolbox.models.PyTorchModel(
        model, bounds=(-1, 1), num_classes=10, preprocessing=(mean, std))

    # get source image and label
    my_transform = transforms.Compose([
        transforms.ToTensor(), 
        transforms.Normalize(mean=[0.5], std=[0.5])
        ])

    test_data = torchvision.datasets.MNIST(
            root='/home/xuzihao/MNIST_Test2/mnist/',
            train=False,
            download=DOWNLOAD_MNIST,
            transform=my_transform
        )

    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=True)

    for batch_idx, (data, target) in enumerate(test_loader):    
        label = target.data.numpy()[0]
        print('label', label)
        image = data.squeeze(0).cpu().numpy()
        plt.subplot(1,2,1)
        my_show_transform(image.squeeze(), use_gray)
        predict = np.argmax(fmodel.predictions(image))
        print('predicted class', predict)
        
        method_name = 'CarliniWagnerL2Attack'
        save_path = os.path.join(r'log/result_pic', method_name)
        makedirs(save_path)

        attack = foolbox.attacks.CarliniWagnerL2Attack()# (fmodel)
        
        criterion = foolbox.criteria.Misclassification()
        adversarial = foolbox.Adversarial(fmodel, criterion, image, np.array(label, dtype=np.int64), distance=foolbox.distances.MSE)
        attack(adversarial)
        adversarial = adversarial.image

        adversarial_predict = np.argmax(fmodel.predictions(adversarial))
        print('adversarial class', adversarial_predict)
        plt.subplot(1,2,2)

        if use_gray:
            plt.imshow(adversarial.squeeze(), cmap ='gray') # 
        else:
            plt.imshow(adversarial.squeeze()) # , cmap ='gray'

        # plt.savefig(os.path.join(save_path, 'example.png'))
        plt.show()

        # with open(r'log/log.txt','a') as f:
          #   f.write(method_name + ' : ODE ' + str(predict) + ' -> ' + str(adversarial_predict)+ '\n')
        break



    '''
    logger.info(model)
    logger.info('Number of parameters: {}'.format(count_parameters(model)))

    criterion = nn.CrossEntropyLoss().to(device)

    train_loader, test_loader, train_eval_loader = get_mnist_loaders(
        args.data_aug, args.batch_size, args.test_batch_size
    )

    data_gen = inf_generator(train_loader)
    batches_per_epoch = len(train_loader)

    lr_fn = learning_rate_with_decay(
        args.batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],
        decay_rates=[1, 0.1, 0.01, 0.001]
    )

    # optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, momentum=0.9)

    best_acc = 0
    batch_time_meter = RunningAverageMeter()
    f_nfe_meter = RunningAverageMeter()
    b_nfe_meter = RunningAverageMeter()
    end = time.time()

    for itr in range(args.nepochs * batches_per_epoch):

        for param_group in optimizer.param_groups:
            param_group['lr'] = lr_fn(itr)

        optimizer.zero_grad()
        x, y = data_gen.__next__()
        x = x.to(device)
        y = y.to(device)
        logits = model(x)
        loss = criterion(logits, y)

        if is_odenet:
            nfe_forward = feature_layers[0].nfe
            feature_layers[0].nfe = 0

        loss.backward()
        optimizer.step()

        if is_odenet:
            nfe_backward = feature_layers[0].nfe
            feature_layers[0].nfe = 0

        batch_time_meter.update(time.time() - end)
        if is_odenet:
            f_nfe_meter.update(nfe_forward)
            b_nfe_meter.update(nfe_backward)
        end = time.time()

        if itr % batches_per_epoch == 0:
            with torch.no_grad():
                train_acc = accuracy(model, train_eval_loader)
                val_acc = accuracy(model, test_loader)
                if val_acc > best_acc:
                    torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth'))
                    best_acc = val_acc
                logger.info(
                    "Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | "
                    "Train Acc {:.4f} | Test Acc {:.4f}".format(
                        itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg,
                        b_nfe_meter.avg, train_acc, val_acc
                    )
                )
    '''

Namespace(adjoint=False, batch_size=128, continuing=False, data_aug=True, debug=False, downsampling_method='res', gpu=0, lr=0.1, nepochs=160, network='odenet', save='./experiment1', test_batch_size=1000, tol=0.001)
D:\Xzh\John计算机前沿课程\Group_Project\torchdiffeq\fooling\ode_fooling.py
import argparse
import logging
import os
import time

import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torchvision.utils import save_image

import foolbox
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.gridspec as gridspec

DOWNLOAD_MNIST = False 
use_gray = False       

parser = argparse.ArgumentParser()
parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')
parser.add_argument('--tol', type=float, default=1e-3)
parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])
parser.add_argument('--downsampling-method', type=str, default='res', choices=['conv', 'res'])
parser.add_argument('--nepochs', type=int, default=160)
parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])
parser.add_argument('--lr', type=float, default=0.1)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--continuing', type=eval, default=False, choices=[True, False])
parser.add_argument('--save', type=str, default='./experiment1')
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint


def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)


def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


def norm(dim):
    return nn.GroupNorm(min(32, dim), dim)


def my_show_transform(x, use_gray):
    x = (x + 1.0) / 2.0
    """Imshow for Tensor."""
    x = np.clip(x, 0, 1)
    if use_gray:
        plt.imshow(x, cmap ='gray')
    else:
        plt.imshow(x)
    return x


class ResBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(ResBlock, self).__init__()
        self.norm1 = norm(inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.norm2 = norm(planes)
        self.conv2 = conv3x3(planes, planes)

    def forward(self, x):
        shortcut = x

        out = self.relu(self.norm1(x))

        if self.downsample is not None:
            shortcut = self.downsample(out)

        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)

        return out + shortcut


class ODEfunc(nn.Module):

    def __init__(self, dim):
        super(ODEfunc, self).__init__()
        self.norm1 = norm(dim)
        self.relu = nn.ReLU(inplace=True)
        self.conv1 = conv3x3(dim, dim)
        self.norm2 = norm(dim)
        self.conv2 = conv3x3(dim, dim)
        self.norm3 = norm(dim)
        self.nfe = 0

    def forward(self, t, x):
        self.nfe += 1
        out = self.norm1(x)
        out = self.relu(out)
        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.norm3(out)
        return out


class ODEBlock(nn.Module):

    def __init__(self, odefunc):
        super(ODEBlock, self).__init__()
        self.odefunc = odefunc
        self.integration_time = torch.tensor([0, 1]).float()

    def forward(self, x):
        self.integration_time = self.integration_time.type_as(x)
        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)
        return out[1]

    @property
    def nfe(self):
        return self.odefunc.nfe

    @nfe.setter
    def nfe(self, value):
        self.odefunc.nfe = value


class Flatten(nn.Module):

    def __init__(self):
        super(Flatten, self).__init__()

    def forward(self, x):
        shape = torch.prod(torch.tensor(x.shape[1:])).item()
        return x.view(-1, shape)


class RunningAverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self, momentum=0.99):
        self.momentum = momentum
        self.reset()

    def reset(self):
        self.val = None
        self.avg = 0

    def update(self, val):
        if self.val is None:
            self.avg = val
        else:
            self.avg = self.avg * self.momentum + val * (1 - self.momentum)
        self.val = val


def inf_generator(iterable):
    """Allows training with DataLoaders in a single infinite loop:
        for i, (x, y) in enumerate(inf_generator(train_loader)):
    """
    iterator = iterable.__iter__()
    while True:
        try:
            yield iterator.__next__()
        except StopIteration:
            iterator = iterable.__iter__()


def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):
    initial_learning_rate = args.lr * batch_size / batch_denom

    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]
    vals = [initial_learning_rate * decay for decay in decay_rates]

    def learning_rate_fn(itr):
        lt = [itr < b for b in boundaries] + [True]
        i = np.argmax(lt)
        return vals[i]

    return learning_rate_fn


def one_hot(x, K):
    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)


def accuracy(model, dataset_loader):
    total_correct = 0
    for x, y in dataset_loader:
        x = x.to(device)
        y = one_hot(np.array(y.numpy()), 10)

        target_class = np.argmax(y, axis=1)
        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)
        total_correct += np.sum(predicted_class == target_class)
    return total_correct / len(dataset_loader.dataset)


def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def makedirs(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):
    logger = logging.getLogger()
    if debug:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logger.setLevel(level)
    if saving:
        info_file_handler = logging.FileHandler(logpath, mode="a")
        info_file_handler.setLevel(level)
        logger.addHandler(info_file_handler)
    if displaying:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        logger.addHandler(console_handler)
    logger.info(filepath)
    with open(filepath, "r") as f:
        logger.info(f.read())

    for f in package_files:
        logger.info(f)
        with open(f, "r") as package_f:
            logger.info(package_f.read())

    return logger


if __name__ == '__main__':

    makedirs(args.save)
    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)

    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')

    is_odenet = args.network == 'odenet'

    if args.downsampling_method == 'conv':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
        ]
    elif args.downsampling_method == 'res':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
        ]

    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]
    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]

    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)
    
    # pay attention to this!! 
    SET_CONTINUE = True
    if args.continuing or SET_CONTINUE:
        model.load_state_dict(torch.load('model.pth')['state_dict'])

    mean = np.array([0.5])
    std = np.array([0.5])

    fmodel = foolbox.models.PyTorchModel(
        model, bounds=(-1, 1), num_classes=10, preprocessing=(mean, std))

    # get source image and label
    my_transform = transforms.Compose([
        transforms.ToTensor(), 
        transforms.Normalize(mean=[0.5], std=[0.5])
        ])

    test_data = torchvision.datasets.MNIST(
            root='./mnist',
            train=False,
            download=DOWNLOAD_MNIST,
            transform=my_transform
        )

    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=True)

    for batch_idx, (data, target) in enumerate(test_loader):    
        label = target.data.numpy()[0]
        print('label', label)
        image = data.squeeze(0).cpu().numpy()
        plt.subplot(1,2,1)
        my_show_transform(image.squeeze(), use_gray)
        predict = np.argmax(fmodel.predictions(image))
        print('predicted class', predict)
        
        method_name = 'CarliniWagnerL2Attack'
        save_path = os.path.join(r'log/result_pic', method_name)
        makedirs(save_path)

        attack = foolbox.attacks.CarliniWagnerL2Attack()# (fmodel)
        
        criterion = foolbox.criteria.Misclassification()
        adversarial = foolbox.Adversarial(fmodel, criterion, image, np.array(label, dtype=np.int64), distance=foolbox.distances.MSE)
        attack(adversarial)
        adversarial = adversarial.image

        adversarial_predict = np.argmax(fmodel.predictions(adversarial))
        print('adversarial class', adversarial_predict)
        plt.subplot(1,2,2)

        if use_gray:
            plt.imshow(adversarial.squeeze(), cmap ='gray') # 
        else:
            plt.imshow(adversarial.squeeze()) # , cmap ='gray'

        # plt.savefig(os.path.join(save_path, 'example.png'))
        plt.show()

        # with open(r'log/log.txt','a') as f:
          #   f.write(method_name + ' : ODE ' + str(predict) + ' -> ' + str(adversarial_predict)+ '\n')
        break
Namespace(adjoint=False, batch_size=128, continuing=False, data_aug=True, debug=False, downsampling_method='res', gpu=0, lr=0.1, nepochs=160, network='odenet', save='./experiment1', test_batch_size=1000, tol=0.001)
starting optimization with const = 0.01
loss: 0.08982403755187988; best overall distance: normalized MSE = inf
loss: 0.09001105166506022; best overall distance: normalized MSE = inf
loss: 0.08979663503007032; best overall distance: normalized MSE = inf
loss: 0.08981552508252208; best overall distance: normalized MSE = inf
loss: 0.0898925293510547; best overall distance: normalized MSE = inf
loss: 0.08985022368608042; best overall distance: normalized MSE = inf
loss: 0.08977382191689685; best overall distance: normalized MSE = inf
loss: 0.08975510803924408; best overall distance: normalized MSE = inf
loss: 0.08979062050348148; best overall distance: normalized MSE = inf
loss: 0.08981315907440149; best overall distance: normalized MSE = inf
loss: 0.08979291796742472; best overall distance: normalized MSE = inf
loss: 0.08975772585137748; best overall distance: normalized MSE = inf
loss: 0.08974351549055427; best overall distance: normalized MSE = inf
loss: 0.08975503160792869; best overall distance: normalized MSE = inf
loss: 0.08976911632693373; best overall distance: normalized MSE = inf
loss: 0.08976768919936148; best overall distance: normalized MSE = inf
loss: 0.08975410801416729; best overall distance: normalized MSE = inf
loss: 0.08974239830393345; best overall distance: normalized MSE = inf
loss: 0.08974054360412993; best overall distance: normalized MSE = inf
loss: 0.089745065732277; best overall distance: normalized MSE = inf
loss: 0.08974798862909665; best overall distance: normalized MSE = inf
loss: 0.08974569455342135; best overall distance: normalized MSE = inf
loss: 0.08974028843396809; best overall distance: normalized MSE = inf
loss: 0.08973597815260291; best overall distance: normalized MSE = inf
loss: 0.08973514593584696; best overall distance: normalized MSE = inf
loss: 0.08973686918587191; best overall distance: normalized MSE = inf
loss: 0.0897382129036123; best overall distance: normalized MSE = inf
loss: 0.08973676324734697; best overall distance: normalized MSE = inf
loss: 0.08973341180797434; best overall distance: normalized MSE = inf
loss: 0.08973096607980552; best overall distance: normalized MSE = inf
loss: 0.08973122028517537; best overall distance: normalized MSE = inf
loss: 0.08973264816915616; best overall distance: normalized MSE = inf
loss: 0.08973273442941718; best overall distance: normalized MSE = inf
loss: 0.08973097424430307; best overall distance: normalized MSE = inf
loss: 0.08972913002711722; best overall distance: normalized MSE = inf
loss: 0.08972875774663408; best overall distance: normalized MSE = inf
loss: 0.08972930407500826; best overall distance: normalized MSE = inf
loss: 0.08972946623165626; best overall distance: normalized MSE = inf
loss: 0.08972867722302909; best overall distance: normalized MSE = inf
loss: 0.08972772947279736; best overall distance: normalized MSE = inf
loss: 0.08972729569650255; best overall distance: normalized MSE = inf
loss: 0.08972731744259363; best overall distance: normalized MSE = inf
loss: 0.08972738642885815; best overall distance: normalized MSE = inf
loss: 0.089727107254148; best overall distance: normalized MSE = inf
loss: 0.0897266424173722; best overall distance: normalized MSE = inf
loss: 0.08972620709508192; best overall distance: normalized MSE = inf
loss: 0.08972596624109429; best overall distance: normalized MSE = inf
loss: 0.0897260282485513; best overall distance: normalized MSE = inf
loss: 0.08972603950998746; best overall distance: normalized MSE = inf
loss: 0.08972570687707047; best overall distance: normalized MSE = inf
loss: 0.08972537386231125; best overall distance: normalized MSE = inf
loss: 0.08972523934906348; best overall distance: normalized MSE = inf
loss: 0.08972526624100283; best overall distance: normalized MSE = inf
loss: 0.08972522728086915; best overall distance: normalized MSE = inf
loss: 0.0897250159745454; best overall distance: normalized MSE = inf
loss: 0.08972481650911504; best overall distance: normalized MSE = inf
loss: 0.08972480840660865; best overall distance: normalized MSE = inf
loss: 0.08972479538497283; best overall distance: normalized MSE = inf
loss: 0.08972472646652023; best overall distance: normalized MSE = inf
loss: 0.08972458750533406; best overall distance: normalized MSE = inf
loss: 0.08972449680848513; best overall distance: normalized MSE = inf
loss: 0.08972449956170749; best overall distance: normalized MSE = inf
loss: 0.08972448049928061; best overall distance: normalized MSE = inf
loss: 0.08972444724058733; best overall distance: normalized MSE = inf
loss: 0.08972438183263876; best overall distance: normalized MSE = inf
loss: 0.08972434375056765; best overall distance: normalized MSE = inf
loss: 0.08972432868671604; best overall distance: normalized MSE = inf
loss: 0.08972433676157379; best overall distance: normalized MSE = inf
loss: 0.08972428075852804; best overall distance: normalized MSE = inf
loss: 0.08972423887898913; best overall distance: normalized MSE = inf
loss: 0.08972423943603644; best overall distance: normalized MSE = inf
/Users/limuyang/Nustore Files/First Half of Junior Year/John/torchdiffeq/fooling/ode_fooling.py
import argparse
import logging
import os

import foolbox
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

DOWNLOAD_MNIST = False
use_gray = False

parser = argparse.ArgumentParser()
parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')
parser.add_argument('--tol', type=float, default=1e-3)
parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])
parser.add_argument('--downsampling-method', type=str, default='res', choices=['conv', 'res'])
parser.add_argument('--nepochs', type=int, default=160)
parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])
parser.add_argument('--lr', type=float, default=0.1)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--continuing', type=eval, default=False, choices=[True, False])
parser.add_argument('--save', type=str, default='./experiment1')
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint


def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)


def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


def norm(dim):
    return nn.GroupNorm(min(32, dim), dim)


def my_show_transform(x, use_gray):
    x = (x + 1.0) / 2.0
    """Imshow for Tensor."""
    x = np.clip(x, 0, 1)
    if use_gray:
        plt.imshow(x, cmap='gray')
    else:
        plt.imshow(x)
    return x


class ResBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(ResBlock, self).__init__()
        self.norm1 = norm(inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.norm2 = norm(planes)
        self.conv2 = conv3x3(planes, planes)

    def forward(self, x):
        shortcut = x

        out = self.relu(self.norm1(x))

        if self.downsample is not None:
            shortcut = self.downsample(out)

        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)

        return out + shortcut


class ODEfunc(nn.Module):

    def __init__(self, dim):
        super(ODEfunc, self).__init__()
        self.norm1 = norm(dim)
        self.relu = nn.ReLU(inplace=True)
        self.conv1 = conv3x3(dim, dim)
        self.norm2 = norm(dim)
        self.conv2 = conv3x3(dim, dim)
        self.norm3 = norm(dim)
        self.nfe = 0

    def forward(self, t, x):
        self.nfe += 1
        out = self.norm1(x)
        out = self.relu(out)
        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.norm3(out)
        return out


class ODEBlock(nn.Module):

    def __init__(self, odefunc):
        super(ODEBlock, self).__init__()
        self.odefunc = odefunc
        self.integration_time = torch.tensor([0, 1]).float()

    def forward(self, x):
        self.integration_time = self.integration_time.type_as(x)
        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)
        return out[1]

    @property
    def nfe(self):
        return self.odefunc.nfe

    @nfe.setter
    def nfe(self, value):
        self.odefunc.nfe = value


class Flatten(nn.Module):

    def __init__(self):
        super(Flatten, self).__init__()

    def forward(self, x):
        shape = torch.prod(torch.tensor(x.shape[1:])).item()
        return x.view(-1, shape)


class RunningAverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self, momentum=0.99):
        self.momentum = momentum
        self.reset()

    def reset(self):
        self.val = None
        self.avg = 0

    def update(self, val):
        if self.val is None:
            self.avg = val
        else:
            self.avg = self.avg * self.momentum + val * (1 - self.momentum)
        self.val = val


def inf_generator(iterable):
    """Allows training with DataLoaders in a single infinite loop:
        for i, (x, y) in enumerate(inf_generator(train_loader)):
    """
    iterator = iterable.__iter__()
    while True:
        try:
            yield iterator.__next__()
        except StopIteration:
            iterator = iterable.__iter__()


def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):
    initial_learning_rate = args.lr * batch_size / batch_denom

    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]
    vals = [initial_learning_rate * decay for decay in decay_rates]

    def learning_rate_fn(itr):
        lt = [itr < b for b in boundaries] + [True]
        i = np.argmax(lt)
        return vals[i]

    return learning_rate_fn


def one_hot(x, K):
    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)


def accuracy(model, dataset_loader):
    total_correct = 0
    for x, y in dataset_loader:
        x = x.to(device)
        y = one_hot(np.array(y.numpy()), 10)

        target_class = np.argmax(y, axis=1)
        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)
        total_correct += np.sum(predicted_class == target_class)
    return total_correct / len(dataset_loader.dataset)


def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def makedirs(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):
    logger = logging.getLogger()
    if debug:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logger.setLevel(level)
    if saving:
        info_file_handler = logging.FileHandler(logpath, mode="a")
        info_file_handler.setLevel(level)
        logger.addHandler(info_file_handler)
    if displaying:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        logger.addHandler(console_handler)
    logger.info(filepath)
    with open(filepath, "r") as f:
        logger.info(f.read())

    for f in package_files:
        logger.info(f)
        with open(f, "r") as package_f:
            logger.info(package_f.read())

    return logger


if __name__ == '__main__':

    makedirs(args.save)
    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)

    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')

    is_odenet = args.network == 'odenet'

    if args.downsampling_method == 'conv':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
        ]
    elif args.downsampling_method == 'res':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
        ]

    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]
    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]

    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)

    # pay attention to this!! 
    SET_CONTINUE = True
    if args.continuing or SET_CONTINUE:
        model.load_state_dict(torch.load('model.pth')['state_dict'])

    mean = np.array([0.5])
    std = np.array([0.5])

    fmodel = foolbox.models.PyTorchModel(
        model, bounds=(-1, 1), num_classes=10, preprocessing=(mean, std))

    # get source image and label
    my_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])

    test_data = torchvision.datasets.MNIST(
        root='./mnist',
        train=False,
        download=DOWNLOAD_MNIST,
        transform=my_transform
    )

    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)

    for batch_idx, (data, target) in enumerate(test_loader):
        label = target.data.numpy()[0]
        print('label', label)
        image = data.squeeze(0).cpu().numpy()
        plt.subplot(1, 2, 1)
        my_show_transform(image.squeeze(), use_gray)
        predict = np.argmax(fmodel.predictions(image))
        print('predicted class', predict)

        method_name = 'CarliniWagnerL2Attack'
        save_path = os.path.join(r'log/result_pic', method_name)
        makedirs(save_path)

        attack = foolbox.attacks.CarliniWagnerL2Attack()  # (fmodel)

        criterion = foolbox.criteria.Misclassification()
        adversarial = foolbox.Adversarial(fmodel, criterion, image, np.array(label, dtype=np.int64),
                                          distance=foolbox.distances.MSE)
        attack(adversarial)
        adversarial = adversarial.image

        adversarial_predict = np.argmax(fmodel.predictions(adversarial))
        print('adversarial class', adversarial_predict)
        plt.subplot(1, 2, 2)

        if use_gray:
            plt.imshow(adversarial.squeeze(), cmap='gray')  #
        else:
            plt.imshow(adversarial.squeeze())  # , cmap ='gray'

        # plt.savefig(os.path.join(save_path, 'example.png'))
        plt.show()

        # with open(r'log/log.txt','a') as f:
        #   f.write(method_name + ' : ODE ' + str(predict) + ' -> ' + str(adversarial_predict)+ '\n')
        break

Namespace(adjoint=False, batch_size=128, continuing=False, data_aug=True, debug=False, downsampling_method='res', gpu=0, lr=0.1, nepochs=160, network='odenet', save='./experiment1', test_batch_size=1000, tol=0.001)
/Users/limuyang/Nustore Files/First Half of Junior Year/John/torchdiffeq/fooling/ode_fooling.py
import argparse
import logging
import os

import foolbox
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

DOWNLOAD_MNIST = False
use_gray = False

parser = argparse.ArgumentParser()
parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')
parser.add_argument('--tol', type=float, default=1e-3)
parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])
parser.add_argument('--downsampling-method', type=str, default='res', choices=['conv', 'res'])
parser.add_argument('--nepochs', type=int, default=160)
parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])
parser.add_argument('--lr', type=float, default=0.1)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--continuing', type=eval, default=False, choices=[True, False])
parser.add_argument('--save', type=str, default='./experiment1')
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint


def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)


def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


def norm(dim):
    return nn.GroupNorm(min(32, dim), dim)


def my_show_transform(x, use_gray):
    x = (x + 1.0) / 2.0
    """Imshow for Tensor."""
    x = np.clip(x, 0, 1)
    if use_gray:
        plt.imshow(x, cmap='gray')
    else:
        plt.imshow(x)
    return x


class ResBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(ResBlock, self).__init__()
        self.norm1 = norm(inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.norm2 = norm(planes)
        self.conv2 = conv3x3(planes, planes)

    def forward(self, x):
        shortcut = x

        out = self.relu(self.norm1(x))

        if self.downsample is not None:
            shortcut = self.downsample(out)

        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)

        return out + shortcut


class ODEfunc(nn.Module):

    def __init__(self, dim):
        super(ODEfunc, self).__init__()
        self.norm1 = norm(dim)
        self.relu = nn.ReLU(inplace=True)
        self.conv1 = conv3x3(dim, dim)
        self.norm2 = norm(dim)
        self.conv2 = conv3x3(dim, dim)
        self.norm3 = norm(dim)
        self.nfe = 0

    def forward(self, t, x):
        self.nfe += 1
        out = self.norm1(x)
        out = self.relu(out)
        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.norm3(out)
        return out


class ODEBlock(nn.Module):

    def __init__(self, odefunc):
        super(ODEBlock, self).__init__()
        self.odefunc = odefunc
        self.integration_time = torch.tensor([0, 1]).float()

    def forward(self, x):
        self.integration_time = self.integration_time.type_as(x)
        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)
        return out[1]

    @property
    def nfe(self):
        return self.odefunc.nfe

    @nfe.setter
    def nfe(self, value):
        self.odefunc.nfe = value


class Flatten(nn.Module):

    def __init__(self):
        super(Flatten, self).__init__()

    def forward(self, x):
        shape = torch.prod(torch.tensor(x.shape[1:])).item()
        return x.view(-1, shape)


class RunningAverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self, momentum=0.99):
        self.momentum = momentum
        self.reset()

    def reset(self):
        self.val = None
        self.avg = 0

    def update(self, val):
        if self.val is None:
            self.avg = val
        else:
            self.avg = self.avg * self.momentum + val * (1 - self.momentum)
        self.val = val


def inf_generator(iterable):
    """Allows training with DataLoaders in a single infinite loop:
        for i, (x, y) in enumerate(inf_generator(train_loader)):
    """
    iterator = iterable.__iter__()
    while True:
        try:
            yield iterator.__next__()
        except StopIteration:
            iterator = iterable.__iter__()


def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):
    initial_learning_rate = args.lr * batch_size / batch_denom

    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]
    vals = [initial_learning_rate * decay for decay in decay_rates]

    def learning_rate_fn(itr):
        lt = [itr < b for b in boundaries] + [True]
        i = np.argmax(lt)
        return vals[i]

    return learning_rate_fn


def one_hot(x, K):
    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)


def accuracy(model, dataset_loader):
    total_correct = 0
    for x, y in dataset_loader:
        x = x.to(device)
        y = one_hot(np.array(y.numpy()), 10)

        target_class = np.argmax(y, axis=1)
        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)
        total_correct += np.sum(predicted_class == target_class)
    return total_correct / len(dataset_loader.dataset)


def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def makedirs(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):
    logger = logging.getLogger()
    if debug:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logger.setLevel(level)
    if saving:
        info_file_handler = logging.FileHandler(logpath, mode="a")
        info_file_handler.setLevel(level)
        logger.addHandler(info_file_handler)
    if displaying:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        logger.addHandler(console_handler)
    logger.info(filepath)
    with open(filepath, "r") as f:
        logger.info(f.read())

    for f in package_files:
        logger.info(f)
        with open(f, "r") as package_f:
            logger.info(package_f.read())

    return logger


if __name__ == '__main__':

    makedirs(args.save)
    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)

    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')

    is_odenet = args.network == 'odenet'

    if args.downsampling_method == 'conv':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
        ]
    elif args.downsampling_method == 'res':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
        ]

    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]
    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]

    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)

    # pay attention to this!! 
    SET_CONTINUE = True
    if args.continuing or SET_CONTINUE:
        model.load_state_dict(torch.load('model.pth')['state_dict'], map_location='cpu')

    mean = np.array([0.5])
    std = np.array([0.5])

    fmodel = foolbox.models.PyTorchModel(
        model, bounds=(-1, 1), num_classes=10, preprocessing=(mean, std))

    # get source image and label
    my_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])

    test_data = torchvision.datasets.MNIST(
        root='./mnist',
        train=False,
        download=DOWNLOAD_MNIST,
        transform=my_transform
    )

    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)

    for batch_idx, (data, target) in enumerate(test_loader):
        label = target.data.numpy()[0]
        print('label', label)
        image = data.squeeze(0).cpu().numpy()
        plt.subplot(1, 2, 1)
        my_show_transform(image.squeeze(), use_gray)
        predict = np.argmax(fmodel.predictions(image))
        print('predicted class', predict)

        method_name = 'CarliniWagnerL2Attack'
        save_path = os.path.join(r'log/result_pic', method_name)
        makedirs(save_path)

        attack = foolbox.attacks.CarliniWagnerL2Attack()  # (fmodel)

        criterion = foolbox.criteria.Misclassification()
        adversarial = foolbox.Adversarial(fmodel, criterion, image, np.array(label, dtype=np.int64),
                                          distance=foolbox.distances.MSE)
        attack(adversarial)
        adversarial = adversarial.image

        adversarial_predict = np.argmax(fmodel.predictions(adversarial))
        print('adversarial class', adversarial_predict)
        plt.subplot(1, 2, 2)

        if use_gray:
            plt.imshow(adversarial.squeeze(), cmap='gray')  #
        else:
            plt.imshow(adversarial.squeeze())  # , cmap ='gray'

        # plt.savefig(os.path.join(save_path, 'example.png'))
        plt.show()

        # with open(r'log/log.txt','a') as f:
        #   f.write(method_name + ' : ODE ' + str(predict) + ' -> ' + str(adversarial_predict)+ '\n')
        break

Namespace(adjoint=False, batch_size=128, continuing=False, data_aug=True, debug=False, downsampling_method='res', gpu=0, lr=0.1, nepochs=160, network='odenet', save='./experiment1', test_batch_size=1000, tol=0.001)
/Users/limuyang/Nustore Files/First Half of Junior Year/John/torchdiffeq/fooling/ode_fooling.py
import argparse
import logging
import os

import foolbox
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

DOWNLOAD_MNIST = False
use_gray = False

parser = argparse.ArgumentParser()
parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')
parser.add_argument('--tol', type=float, default=1e-3)
parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])
parser.add_argument('--downsampling-method', type=str, default='res', choices=['conv', 'res'])
parser.add_argument('--nepochs', type=int, default=160)
parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])
parser.add_argument('--lr', type=float, default=0.1)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--continuing', type=eval, default=False, choices=[True, False])
parser.add_argument('--save', type=str, default='./experiment1')
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint


def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)


def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


def norm(dim):
    return nn.GroupNorm(min(32, dim), dim)


def my_show_transform(x, use_gray):
    x = (x + 1.0) / 2.0
    """Imshow for Tensor."""
    x = np.clip(x, 0, 1)
    if use_gray:
        plt.imshow(x, cmap='gray')
    else:
        plt.imshow(x)
    return x


class ResBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(ResBlock, self).__init__()
        self.norm1 = norm(inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.norm2 = norm(planes)
        self.conv2 = conv3x3(planes, planes)

    def forward(self, x):
        shortcut = x

        out = self.relu(self.norm1(x))

        if self.downsample is not None:
            shortcut = self.downsample(out)

        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)

        return out + shortcut


class ODEfunc(nn.Module):

    def __init__(self, dim):
        super(ODEfunc, self).__init__()
        self.norm1 = norm(dim)
        self.relu = nn.ReLU(inplace=True)
        self.conv1 = conv3x3(dim, dim)
        self.norm2 = norm(dim)
        self.conv2 = conv3x3(dim, dim)
        self.norm3 = norm(dim)
        self.nfe = 0

    def forward(self, t, x):
        self.nfe += 1
        out = self.norm1(x)
        out = self.relu(out)
        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.norm3(out)
        return out


class ODEBlock(nn.Module):

    def __init__(self, odefunc):
        super(ODEBlock, self).__init__()
        self.odefunc = odefunc
        self.integration_time = torch.tensor([0, 1]).float()

    def forward(self, x):
        self.integration_time = self.integration_time.type_as(x)
        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)
        return out[1]

    @property
    def nfe(self):
        return self.odefunc.nfe

    @nfe.setter
    def nfe(self, value):
        self.odefunc.nfe = value


class Flatten(nn.Module):

    def __init__(self):
        super(Flatten, self).__init__()

    def forward(self, x):
        shape = torch.prod(torch.tensor(x.shape[1:])).item()
        return x.view(-1, shape)


class RunningAverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self, momentum=0.99):
        self.momentum = momentum
        self.reset()

    def reset(self):
        self.val = None
        self.avg = 0

    def update(self, val):
        if self.val is None:
            self.avg = val
        else:
            self.avg = self.avg * self.momentum + val * (1 - self.momentum)
        self.val = val


def inf_generator(iterable):
    """Allows training with DataLoaders in a single infinite loop:
        for i, (x, y) in enumerate(inf_generator(train_loader)):
    """
    iterator = iterable.__iter__()
    while True:
        try:
            yield iterator.__next__()
        except StopIteration:
            iterator = iterable.__iter__()


def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):
    initial_learning_rate = args.lr * batch_size / batch_denom

    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]
    vals = [initial_learning_rate * decay for decay in decay_rates]

    def learning_rate_fn(itr):
        lt = [itr < b for b in boundaries] + [True]
        i = np.argmax(lt)
        return vals[i]

    return learning_rate_fn


def one_hot(x, K):
    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)


def accuracy(model, dataset_loader):
    total_correct = 0
    for x, y in dataset_loader:
        x = x.to(device)
        y = one_hot(np.array(y.numpy()), 10)

        target_class = np.argmax(y, axis=1)
        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)
        total_correct += np.sum(predicted_class == target_class)
    return total_correct / len(dataset_loader.dataset)


def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def makedirs(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):
    logger = logging.getLogger()
    if debug:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logger.setLevel(level)
    if saving:
        info_file_handler = logging.FileHandler(logpath, mode="a")
        info_file_handler.setLevel(level)
        logger.addHandler(info_file_handler)
    if displaying:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        logger.addHandler(console_handler)
    logger.info(filepath)
    with open(filepath, "r") as f:
        logger.info(f.read())

    for f in package_files:
        logger.info(f)
        with open(f, "r") as package_f:
            logger.info(package_f.read())

    return logger


if __name__ == '__main__':

    makedirs(args.save)
    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)

    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')

    is_odenet = args.network == 'odenet'

    if args.downsampling_method == 'conv':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
        ]
    elif args.downsampling_method == 'res':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
        ]

    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]
    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]

    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)

    # pay attention to this!! 
    SET_CONTINUE = True
    if args.continuing or SET_CONTINUE:
        model.load_state_dict(torch.load('model.pth', map_location='cpu')['state_dict'])

    mean = np.array([0.5])
    std = np.array([0.5])

    fmodel = foolbox.models.PyTorchModel(
        model, bounds=(-1, 1), num_classes=10, preprocessing=(mean, std))

    # get source image and label
    my_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])

    test_data = torchvision.datasets.MNIST(
        root='./mnist',
        train=False,
        download=DOWNLOAD_MNIST,
        transform=my_transform
    )

    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)

    for batch_idx, (data, target) in enumerate(test_loader):
        label = target.data.numpy()[0]
        print('label', label)
        image = data.squeeze(0).cpu().numpy()
        plt.subplot(1, 2, 1)
        my_show_transform(image.squeeze(), use_gray)
        predict = np.argmax(fmodel.predictions(image))
        print('predicted class', predict)

        method_name = 'CarliniWagnerL2Attack'
        save_path = os.path.join(r'log/result_pic', method_name)
        makedirs(save_path)

        attack = foolbox.attacks.CarliniWagnerL2Attack()  # (fmodel)

        criterion = foolbox.criteria.Misclassification()
        adversarial = foolbox.Adversarial(fmodel, criterion, image, np.array(label, dtype=np.int64),
                                          distance=foolbox.distances.MSE)
        attack(adversarial)
        adversarial = adversarial.image

        adversarial_predict = np.argmax(fmodel.predictions(adversarial))
        print('adversarial class', adversarial_predict)
        plt.subplot(1, 2, 2)

        if use_gray:
            plt.imshow(adversarial.squeeze(), cmap='gray')  #
        else:
            plt.imshow(adversarial.squeeze())  # , cmap ='gray'

        # plt.savefig(os.path.join(save_path, 'example.png'))
        plt.show()

        # with open(r'log/log.txt','a') as f:
        #   f.write(method_name + ' : ODE ' + str(predict) + ' -> ' + str(adversarial_predict)+ '\n')
        break

Namespace(adjoint=False, batch_size=128, continuing=False, data_aug=True, debug=False, downsampling_method='res', gpu=0, lr=0.1, nepochs=160, network='odenet', save='./experiment1', test_batch_size=1000, tol=0.001)
starting optimization with const = 0.01
loss: 0.09597737312316895; best overall distance: normalized MSE = inf
loss: 0.096139037408866; best overall distance: normalized MSE = inf
loss: 0.09598035954797524; best overall distance: normalized MSE = inf
loss: 0.09599980271304957; best overall distance: normalized MSE = inf
loss: 0.09605872517975513; best overall distance: normalized MSE = inf
loss: 0.09602851898045628; best overall distance: normalized MSE = inf
loss: 0.09597611666002194; best overall distance: normalized MSE = inf
loss: 0.0959661251304351; best overall distance: normalized MSE = inf
loss: 0.09599343282403425; best overall distance: normalized MSE = inf
loss: 0.09600933084264397; best overall distance: normalized MSE = inf
loss: 0.09599519763316494; best overall distance: normalized MSE = inf
loss: 0.09597146481391974; best overall distance: normalized MSE = inf
loss: 0.0959638041854123; best overall distance: normalized MSE = inf
loss: 0.09597371515825216; best overall distance: normalized MSE = inf
loss: 0.09598375761212083; best overall distance: normalized MSE = inf
loss: 0.0959818049443129; best overall distance: normalized MSE = inf
loss: 0.0959716346760979; best overall distance: normalized MSE = inf
loss: 0.09596438433160075; best overall distance: normalized MSE = inf
loss: 0.09596517646350548; best overall distance: normalized MSE = inf
loss: 0.09596959690417861; best overall distance: normalized MSE = inf
loss: 0.09597136749245692; best overall distance: normalized MSE = inf
loss: 0.09596874497758108; best overall distance: normalized MSE = inf
loss: 0.09596483815214014; best overall distance: normalized MSE = inf
loss: 0.09596298567434133; best overall distance: normalized MSE = inf
loss: 0.09596371030242154; best overall distance: normalized MSE = inf
loss: 0.09596489581024799; best overall distance: normalized MSE = inf
loss: 0.09596476714345045; best overall distance: normalized MSE = inf
loss: 0.09596352869994007; best overall distance: normalized MSE = inf
loss: 0.09596224875822372; best overall distance: normalized MSE = inf
loss: 0.09596170401920973; best overall distance: normalized MSE = inf
loss: 0.09596189184710965; best overall distance: normalized MSE = inf
loss: 0.09596213743803673; best overall distance: normalized MSE = inf
loss: 0.09596193848847179; best overall distance: normalized MSE = inf
loss: 0.09596132114937063; best overall distance: normalized MSE = inf
loss: 0.09596072851971257; best overall distance: normalized MSE = inf
loss: 0.09596044742749654; best overall distance: normalized MSE = inf
loss: 0.09596058783587069; best overall distance: normalized MSE = inf
loss: 0.09596069802777493; best overall distance: normalized MSE = inf
loss: 0.09596048133680597; best overall distance: normalized MSE = inf
loss: 0.09596006841602503; best overall distance: normalized MSE = inf
loss: 0.09595982359023765; best overall distance: normalized MSE = inf
loss: 0.09595982688617369; best overall distance: normalized MSE = inf
loss: 0.09595998127595522; best overall distance: normalized MSE = inf
loss: 0.09595986136708234; best overall distance: normalized MSE = inf
loss: 0.0959596113889711; best overall distance: normalized MSE = inf
loss: 0.09595945615656092; best overall distance: normalized MSE = inf
loss: 0.09595945438995841; best overall distance: normalized MSE = inf
loss: 0.09595950815302785; best overall distance: normalized MSE = inf
loss: 0.09595946927613114; best overall distance: normalized MSE = inf
loss: 0.09595928620299674; best overall distance: normalized MSE = inf
loss: 0.09595921523221478; best overall distance: normalized MSE = inf
loss: 0.09595921731408452; best overall distance: normalized MSE = inf
loss: 0.09595927504065913; best overall distance: normalized MSE = inf
loss: 0.09595920277773985; best overall distance: normalized MSE = inf
loss: 0.09595911520424125; best overall distance: normalized MSE = inf
loss: 0.09595904543733923; best overall distance: normalized MSE = inf
loss: 0.09595909566487536; best overall distance: normalized MSE = inf
loss: 0.09595913048295188; best overall distance: normalized MSE = inf
loss: 0.09595905567839509; best overall distance: normalized MSE = inf
loss: 0.09595900752538; best overall distance: normalized MSE = inf
loss: 0.09595899790539988; best overall distance: normalized MSE = inf
loss: 0.0959590433982521; best overall distance: normalized MSE = inf
loss: 0.09595902730972738; best overall distance: normalized MSE = inf
loss: 0.09595895721227862; best overall distance: normalized MSE = inf
loss: 0.09595892709388863; best overall distance: normalized MSE = inf
loss: 0.09595896080165403; best overall distance: normalized MSE = inf
loss: 0.09595895764272427; best overall distance: normalized MSE = inf
loss: 0.09595892209501472; best overall distance: normalized MSE = inf
loss: 0.09595892880366591; best overall distance: normalized MSE = inf
loss: 0.09595892589728465; best overall distance: normalized MSE = inf
loss: 0.0959589361923281; best overall distance: normalized MSE = inf
loss: 0.0959589305544796; best overall distance: normalized MSE = inf
loss: 0.09595889965828974; best overall distance: normalized MSE = inf
loss: 0.09595890393415175; best overall distance: normalized MSE = inf
loss: 0.09595890464901459; best overall distance: normalized MSE = inf
loss: 0.09595889662239643; best overall distance: normalized MSE = inf
loss: 0.09595889669260942; best overall distance: normalized MSE = inf
loss: 0.09595888843905413; best overall distance: normalized MSE = inf
loss: 0.09595888724419638; best overall distance: normalized MSE = inf
loss: 0.09595890183671145; best overall distance: normalized MSE = inf
loss: 0.09595887195850082; best overall distance: normalized MSE = inf
loss: 0.09595888017662219; best overall distance: normalized MSE = inf
loss: 0.09595890900061932; best overall distance: normalized MSE = inf
loss: 0.09595888494754036; best overall distance: normalized MSE = inf
loss: 0.09595887370698619; best overall distance: normalized MSE = inf
loss: 0.09595890849843272; best overall distance: normalized MSE = inf
loss: 0.095958867684094; best overall distance: normalized MSE = inf
loss: 0.09595888597439625; best overall distance: normalized MSE = inf
loss: 0.09595888299911166; best overall distance: normalized MSE = inf
loss: 0.09595887690069503; best overall distance: normalized MSE = inf
loss: 0.0959588785799133; best overall distance: normalized MSE = inf
loss: 0.09595887045230483; best overall distance: normalized MSE = inf
loss: 0.09595886439172319; best overall distance: normalized MSE = inf
loss: 0.09595885747068678; best overall distance: normalized MSE = inf
loss: 0.09595887543451681; best overall distance: normalized MSE = inf
loss: 0.09595886811366654; best overall distance: normalized MSE = inf
loss: 0.0959588687352516; best overall distance: normalized MSE = inf
loss: 0.09595887282208423; best overall distance: normalized MSE = inf
loss: 0.0959588747448288; best overall distance: normalized MSE = inf
loss: 0.09595885883805749; best overall distance: normalized MSE = inf
loss: 0.09595887532952474; best overall distance: normalized MSE = inf
loss: 0.09595888066323824; best overall distance: normalized MSE = inf
loss: 0.09595887390198186; best overall distance: normalized MSE = inf
loss: 0.0959588668642391; best overall distance: normalized MSE = inf
loss: 0.09595886401089956; best overall distance: normalized MSE = inf
loss: 0.0959588526999869; best overall distance: normalized MSE = inf
loss: 0.09595888552510587; best overall distance: normalized MSE = inf
loss: 0.09595886196490028; best overall distance: normalized MSE = inf
loss: 0.09595887163966836; best overall distance: normalized MSE = inf
loss: 0.09595886879200408; best overall distance: normalized MSE = inf
loss: 0.09595888287367416; best overall distance: normalized MSE = inf
loss: 0.0959588479451486; best overall distance: normalized MSE = inf
loss: 0.09595886682924175; best overall distance: normalized MSE = inf
loss: 0.09595887152114302; best overall distance: normalized MSE = inf
loss: 0.09595886413153494; best overall distance: normalized MSE = inf
loss: 0.09595886638664525; best overall distance: normalized MSE = inf
loss: 0.09595886722017895; best overall distance: normalized MSE = inf
loss: 0.09595884973918146; best overall distance: normalized MSE = inf
loss: 0.09595887836097973; best overall distance: normalized MSE = inf
loss: 0.09595886682880518; best overall distance: normalized MSE = inf
loss: 0.09595888551419193; best overall distance: normalized MSE = inf
loss: 0.09595888096060662; best overall distance: normalized MSE = inf
loss: 0.09595885874550732; best overall distance: normalized MSE = inf
loss: 0.09595886308037735; best overall distance: normalized MSE = inf
loss: 0.0959588710116077; best overall distance: normalized MSE = inf
loss: 0.09595887931369362; best overall distance: normalized MSE = inf
loss: 0.09595886520946806; best overall distance: normalized MSE = inf
loss: 0.09595886329545465; best overall distance: normalized MSE = inf
loss: 0.09595885279966751; best overall distance: normalized MSE = inf
loss: 0.09595887780284101; best overall distance: normalized MSE = inf
loss: 0.09595885347473086; best overall distance: normalized MSE = inf
loss: 0.09595887213392416; best overall distance: normalized MSE = inf
loss: 0.09595887104820577; best overall distance: normalized MSE = inf
loss: 0.09595886419789168; best overall distance: normalized MSE = inf
loss: 0.09595885914270184; best overall distance: normalized MSE = inf
loss: 0.09595885885144526; best overall distance: normalized MSE = inf
loss: 0.0959588607486512; best overall distance: normalized MSE = inf
loss: 0.09595886085982784; best overall distance: normalized MSE = inf
loss: 0.0959588594230445; best overall distance: normalized MSE = inf
loss: 0.09595886932176655; best overall distance: normalized MSE = inf
loss: 0.0959588728503877; best overall distance: normalized MSE = inf
loss: 0.09595884803980881; best overall distance: normalized MSE = inf
loss: 0.09595885699629435; best overall distance: normalized MSE = inf
loss: 0.09595886099443306; best overall distance: normalized MSE = inf
loss: 0.09595885510658264; best overall distance: normalized MSE = inf
loss: 0.0959588643340976; best overall distance: normalized MSE = inf
loss: 0.09595886063791113; best overall distance: normalized MSE = inf
loss: 0.09595887656090782; best overall distance: normalized MSE = inf
loss: 0.09595885754199117; best overall distance: normalized MSE = inf
loss: 0.09595887004732503; best overall distance: normalized MSE = inf
loss: 0.0959588446021371; best overall distance: normalized MSE = inf
loss: 0.09595886347189662; best overall distance: normalized MSE = inf
loss: 0.09595886024682841; best overall distance: normalized MSE = inf
loss: 0.09595883784277248; best overall distance: normalized MSE = inf
loss: 0.09595887549861801; best overall distance: normalized MSE = inf
loss: 0.09595885900809663; best overall distance: normalized MSE = inf
loss: 0.09595888077368728; best overall distance: normalized MSE = inf
loss: 0.09595887208823115; best overall distance: normalized MSE = inf
loss: 0.09595886066701496; best overall distance: normalized MSE = inf
loss: 0.09595887698655134; best overall distance: normalized MSE = inf
loss: 0.09595885654518498; best overall distance: normalized MSE = inf
loss: 0.0959588576729584; best overall distance: normalized MSE = inf
loss: 0.09595887890376617; best overall distance: normalized MSE = inf
loss: 0.09595886161470844; best overall distance: normalized MSE = inf
loss: 0.09595887109870091; best overall distance: normalized MSE = inf
loss: 0.09595886948161933; best overall distance: normalized MSE = inf
loss: 0.0959588583787263; best overall distance: normalized MSE = inf
loss: 0.09595887718664017; best overall distance: normalized MSE = inf
loss: 0.09595885894806998; best overall distance: normalized MSE = inf
loss: 0.09595886023773346; best overall distance: normalized MSE = inf
loss: 0.0959588611927029; best overall distance: normalized MSE = inf
loss: 0.0959588608489139; best overall distance: normalized MSE = inf
loss: 0.09595886931791028; best overall distance: normalized MSE = inf
loss: 0.0959588590481144; best overall distance: normalized MSE = inf
loss: 0.09595887856179616; best overall distance: normalized MSE = inf
loss: 0.09595887006551493; best overall distance: normalized MSE = inf
loss: 0.09595885184513464; best overall distance: normalized MSE = inf
loss: 0.09595888025345631; best overall distance: normalized MSE = inf
loss: 0.0959588696762512; best overall distance: normalized MSE = inf
loss: 0.09595885929185898; best overall distance: normalized MSE = inf
loss: 0.09595885955015547; best overall distance: normalized MSE = inf
loss: 0.0959588701037137; best overall distance: normalized MSE = inf
loss: 0.09595885203612853; best overall distance: normalized MSE = inf
loss: 0.09595885177055608; best overall distance: normalized MSE = inf
loss: 0.095958860659739; best overall distance: normalized MSE = inf
loss: 0.09595887896924979; best overall distance: normalized MSE = inf
loss: 0.09595885998853192; best overall distance: normalized MSE = inf
loss: 0.0959588701055327; best overall distance: normalized MSE = inf
loss: 0.09595887074399798; best overall distance: normalized MSE = inf
loss: 0.09595888009702322; best overall distance: normalized MSE = inf
loss: 0.09595887005460099; best overall distance: normalized MSE = inf
loss: 0.0959588698472362; best overall distance: normalized MSE = inf
loss: 0.09595886029230315; best overall distance: normalized MSE = inf
loss: 0.09595887028197467; best overall distance: normalized MSE = inf
loss: 0.0959588706366776; best overall distance: normalized MSE = inf
loss: 0.09595887096045772; best overall distance: normalized MSE = inf
loss: 0.09595887032381142; best overall distance: normalized MSE = inf
loss: 0.09595886991271982; best overall distance: normalized MSE = inf
loss: 0.09595887925665011; best overall distance: normalized MSE = inf
loss: 0.09595887985327864; best overall distance: normalized MSE = inf
loss: 0.09595888023162844; best overall distance: normalized MSE = inf
failed to find adversarial with const = 0.01
starting optimization with const = 0.1
loss: 0.9597737312316895; best overall distance: normalized MSE = inf
loss: 0.959222050034441; best overall distance: normalized MSE = inf
loss: 0.9589682152494788; best overall distance: normalized MSE = inf
loss: 0.9588687780778855; best overall distance: normalized MSE = inf
loss: 0.9588360693771393; best overall distance: normalized MSE = inf
loss: 0.9587986775208265; best overall distance: normalized MSE = inf
loss: 0.9587561524705962; best overall distance: normalized MSE = inf
loss: 0.9587145067518578; best overall distance: normalized MSE = inf
loss: 0.9586739638820291; best overall distance: normalized MSE = inf
loss: 0.9586394489509985; best overall distance: normalized MSE = inf
loss: 0.9586116553051398; best overall distance: normalized MSE = inf
loss: 0.9585966030135751; best overall distance: normalized MSE = inf
loss: 0.9585839154198766; best overall distance: normalized MSE = inf
loss: 0.9585650303633884; best overall distance: normalized MSE = inf
loss: 0.958542990568094; best overall distance: normalized MSE = inf
loss: 0.9585216373670846; best overall distance: normalized MSE = inf
loss: 0.9585049801040442; best overall distance: normalized MSE = inf
loss: 0.9584988377289847; best overall distance: normalized MSE = inf
loss: 0.9584921436849982; best overall distance: normalized MSE = inf
loss: 0.9584795661969111; best overall distance: normalized MSE = inf
loss: 0.9584806324215607; best overall distance: normalized MSE = inf
loss: 0.9584700342733413; best overall distance: normalized MSE = inf
loss: 0.9584496644325555; best overall distance: normalized MSE = inf
loss: 0.9584406605456025; best overall distance: normalized MSE = inf
loss: 0.958435007557273; best overall distance: normalized MSE = inf
loss: 0.9584229291416705; best overall distance: normalized MSE = inf
loss: 0.9584089328069241; best overall distance: normalized MSE = inf
loss: 0.9584043422481046; best overall distance: normalized MSE = inf
loss: 0.9583940495271236; best overall distance: normalized MSE = inf
loss: 0.9583870633505285; best overall distance: normalized MSE = inf
loss: 0.9583850007737056; best overall distance: normalized MSE = inf
loss: 0.9583748967386783; best overall distance: normalized MSE = inf
loss: 0.9583696933928878; best overall distance: normalized MSE = inf
loss: 0.9583656126400456; best overall distance: normalized MSE = inf
loss: 0.9583575583528727; best overall distance: normalized MSE = inf
loss: 0.9583533045370132; best overall distance: normalized MSE = inf
loss: 0.9583495364524425; best overall distance: normalized MSE = inf
loss: 0.9583424271782861; best overall distance: normalized MSE = inf
loss: 0.9583383619319648; best overall distance: normalized MSE = inf
loss: 0.9583304431289434; best overall distance: normalized MSE = inf
loss: 0.9583274438744411; best overall distance: normalized MSE = inf
loss: 0.9583203675225378; best overall distance: normalized MSE = inf
loss: 0.9583175910403953; best overall distance: normalized MSE = inf
loss: 0.9583165786694736; best overall distance: normalized MSE = inf
loss: 0.9583098547998816; best overall distance: normalized MSE = inf
loss: 0.9583019936922939; best overall distance: normalized MSE = inf
loss: 0.9582977327052504; best overall distance: normalized MSE = inf
loss: 0.9582976806210355; best overall distance: normalized MSE = inf
loss: 0.9582910362165422; best overall distance: normalized MSE = inf
loss: 0.958286983310245; best overall distance: normalized MSE = inf
loss: 0.9582859937101603; best overall distance: normalized MSE = inf
loss: 0.9582790488144384; best overall distance: normalized MSE = inf
loss: 0.9582763428799809; best overall distance: normalized MSE = inf
loss: 0.9582759964512662; best overall distance: normalized MSE = inf
loss: 0.9582725587533787; best overall distance: normalized MSE = inf
loss: 0.9582654464058579; best overall distance: normalized MSE = inf
loss: 0.9582731297239662; best overall distance: normalized MSE = inf
loss: 0.9582690654788166; best overall distance: normalized MSE = inf
loss: 0.9582570235943422; best overall distance: normalized MSE = inf
loss: 0.9582570887636394; best overall distance: normalized MSE = inf
loss: 0.9582519020652399; best overall distance: normalized MSE = inf
loss: 0.9582539383787663; best overall distance: normalized MSE = inf
loss: 0.9582489572931081; best overall distance: normalized MSE = inf
loss: 0.9582472580950707; best overall distance: normalized MSE = inf
loss: 0.9582467010710389; best overall distance: normalized MSE = inf
loss: 0.95824109246023; best overall distance: normalized MSE = inf
loss: 0.9582410637987778; best overall distance: normalized MSE = inf
loss: 0.9582384058041499; best overall distance: normalized MSE = inf
loss: 0.9582333974307403; best overall distance: normalized MSE = inf
loss: 0.9582332527730615; best overall distance: normalized MSE = inf
loss: 0.9582276666769758; best overall distance: normalized MSE = inf
loss: 0.9582320562331006; best overall distance: normalized MSE = inf
loss: 0.958228138415143; best overall distance: normalized MSE = inf
loss: 0.9582246410660447; best overall distance: normalized MSE = inf
loss: 0.9582258893642575; best overall distance: normalized MSE = inf
loss: 0.9582209535408766; best overall distance: normalized MSE = inf
loss: 0.958218220830895; best overall distance: normalized MSE = inf
loss: 0.9582151747774333; best overall distance: normalized MSE = inf
loss: 0.9582170934416354; best overall distance: normalized MSE = inf
loss: 0.9582178900483996; best overall distance: normalized MSE = inf
loss: 0.9582123449305073; best overall distance: normalized MSE = inf
loss: 0.9582113922107965; best overall distance: normalized MSE = inf
loss: 0.9582084211986512; best overall distance: normalized MSE = inf
loss: 0.958208703971468; best overall distance: normalized MSE = inf
loss: 0.9582105348818004; best overall distance: normalized MSE = inf
loss: 0.9582060326356441; best overall distance: normalized MSE = inf
loss: 0.9582009055186064; best overall distance: normalized MSE = inf
loss: 0.9581989371683449; best overall distance: normalized MSE = inf
loss: 0.9582023827824742; best overall distance: normalized MSE = inf
loss: 0.9582033949904144; best overall distance: normalized MSE = inf
loss: 0.9581983955344185; best overall distance: normalized MSE = inf
loss: 0.9581968978978694; best overall distance: normalized MSE = inf
loss: 0.9581938187824562; best overall distance: normalized MSE = inf
loss: 0.9581972585525365; best overall distance: normalized MSE = inf
loss: 0.9581989596597851; best overall distance: normalized MSE = inf
loss: 0.9581945373909548; best overall distance: normalized MSE = inf
loss: 0.9581883862614632; best overall distance: normalized MSE = inf
loss: 0.9581862872932106; best overall distance: normalized MSE = inf
loss: 0.9581923454999924; best overall distance: normalized MSE = inf
loss: 0.9581936468835921; best overall distance: normalized MSE = inf
loss: 0.9581889514345676; best overall distance: normalized MSE = inf
loss: 0.958185234060511; best overall distance: normalized MSE = inf
loss: 0.9581827521324158; best overall distance: normalized MSE = inf
loss: 0.9581877885153518; best overall distance: normalized MSE = inf
loss: 0.9581904554041103; best overall distance: normalized MSE = inf
loss: 0.958186522172764; best overall distance: normalized MSE = inf
loss: 0.9581782777793706; best overall distance: normalized MSE = inf
loss: 0.9581949686165899; best overall distance: normalized MSE = inf
loss: 0.9581962375435978; best overall distance: normalized MSE = inf
loss: 0.9581833080388606; best overall distance: normalized MSE = inf
loss: 0.9581853511277587; best overall distance: normalized MSE = inf
loss: 0.9581930745393038; best overall distance: normalized MSE = inf
loss: 0.9581892809597776; best overall distance: normalized MSE = inf
loss: 0.9581802581902594; best overall distance: normalized MSE = inf
loss: 0.9581803828943521; best overall distance: normalized MSE = inf
loss: 0.9581819558050484; best overall distance: normalized MSE = inf
loss: 0.9581715380772948; best overall distance: normalized MSE = inf
loss: 0.9581726816948504; best overall distance: normalized MSE = inf
loss: 0.958171128272079; best overall distance: normalized MSE = inf
loss: 0.9581722009461373; best overall distance: normalized MSE = inf
loss: 0.9581698995316401; best overall distance: normalized MSE = inf
loss: 0.9581735966261477; best overall distance: normalized MSE = inf
loss: 0.9581691877916456; best overall distance: normalized MSE = inf
loss: 0.9581744679016992; best overall distance: normalized MSE = inf
loss: 0.9581781971734018; best overall distance: normalized MSE = inf
loss: 0.9581741829402746; best overall distance: normalized MSE = inf
loss: 0.9581655121408403; best overall distance: normalized MSE = inf
loss: 0.9581808654125781; best overall distance: normalized MSE = inf
loss: 0.9581824335735292; best overall distance: normalized MSE = inf
loss: 0.9581696352455765; best overall distance: normalized MSE = inf
loss: 0.958172644628212; best overall distance: normalized MSE = inf
loss: 0.9581807919079438; best overall distance: normalized MSE = inf
loss: 0.9581766563467682; best overall distance: normalized MSE = inf
loss: 0.9581671528518201; best overall distance: normalized MSE = inf
loss: 0.9581707987003029; best overall distance: normalized MSE = inf
loss: 0.9581732634687796; best overall distance: normalized MSE = inf
loss: 0.9581602623919026; best overall distance: normalized MSE = inf
loss: 0.9581734109669924; best overall distance: normalized MSE = inf
loss: 0.9581818855600432; best overall distance: normalized MSE = inf
loss: 0.9581774836871774; best overall distance: normalized MSE = inf
loss: 0.9581666700541973; best overall distance: normalized MSE = inf
loss: 0.9581636309623719; best overall distance: normalized MSE = inf
loss: 0.958167400979437; best overall distance: normalized MSE = inf
loss: 0.9581557325553149; best overall distance: normalized MSE = inf
loss: 0.958169508096762; best overall distance: normalized MSE = inf
loss: 0.9581776396371424; best overall distance: normalized MSE = inf
loss: 0.9581735395593569; best overall distance: normalized MSE = inf
loss: 0.9581624273676426; best overall distance: normalized MSE = inf
loss: 0.9581606137333438; best overall distance: normalized MSE = inf
loss: 0.9581649348838255; best overall distance: normalized MSE = inf
loss: 0.9581534988246858; best overall distance: normalized MSE = inf
loss: 0.9581655310932548; best overall distance: normalized MSE = inf
loss: 0.9581730919424445; best overall distance: normalized MSE = inf
loss: 0.9581697449088097; best overall distance: normalized MSE = inf
loss: 0.9581584680825472; best overall distance: normalized MSE = inf
loss: 0.9581580507569015; best overall distance: normalized MSE = inf
loss: 0.9581624841317535; best overall distance: normalized MSE = inf
loss: 0.95815085824579; best overall distance: normalized MSE = inf
loss: 0.9581620653858409; best overall distance: normalized MSE = inf
loss: 0.9581701932474971; best overall distance: normalized MSE = inf
loss: 0.9581665933597834; best overall distance: normalized MSE = inf
loss: 0.9581557917874307; best overall distance: normalized MSE = inf
loss: 0.9581533864140511; best overall distance: normalized MSE = inf
loss: 0.9581574882380665; best overall distance: normalized MSE = inf
loss: 0.9581460485002027; best overall distance: normalized MSE = inf
loss: 0.9581600054632873; best overall distance: normalized MSE = inf
loss: 0.9581682673888281; best overall distance: normalized MSE = inf
loss: 0.9581643779063598; best overall distance: normalized MSE = inf
loss: 0.9581537183374167; best overall distance: normalized MSE = inf
loss: 0.9581499819178134; best overall distance: normalized MSE = inf
loss: 0.9581536320969463; best overall distance: normalized MSE = inf
loss: 0.9581432833801955; best overall distance: normalized MSE = inf
loss: 0.9581442530965433; best overall distance: normalized MSE = inf
loss: 0.9581450167577714; best overall distance: normalized MSE = inf
loss: 0.9581442174036057; best overall distance: normalized MSE = inf
loss: 0.9581421990413219; best overall distance: normalized MSE = inf
loss: 0.9581495588412509; best overall distance: normalized MSE = inf
loss: 0.9581453896127642; best overall distance: normalized MSE = inf
loss: 0.9581473607569934; best overall distance: normalized MSE = inf
loss: 0.9581508373841644; best overall distance: normalized MSE = inf
loss: 0.9581479051616043; best overall distance: normalized MSE = inf
loss: 0.9581392244435847; best overall distance: normalized MSE = inf
loss: 0.9581569652538747; best overall distance: normalized MSE = inf
loss: 0.9581572647904978; best overall distance: normalized MSE = inf
loss: 0.9581430653808639; best overall distance: normalized MSE = inf
loss: 0.9581510890740902; best overall distance: normalized MSE = inf
loss: 0.9581608898472042; best overall distance: normalized MSE = inf
loss: 0.9581573093077168; best overall distance: normalized MSE = inf
loss: 0.9581463174894452; best overall distance: normalized MSE = inf
loss: 0.9581445473711938; best overall distance: normalized MSE = inf
loss: 0.9581488054711372; best overall distance: normalized MSE = inf
loss: 0.9581368018407375; best overall distance: normalized MSE = inf
loss: 0.9581501972395927; best overall distance: normalized MSE = inf
loss: 0.9581590360496194; best overall distance: normalized MSE = inf
loss: 0.9581552790710703; best overall distance: normalized MSE = inf
loss: 0.9581432458013297; best overall distance: normalized MSE = inf
loss: 0.958143249922432; best overall distance: normalized MSE = inf
loss: 0.9581487071700394; best overall distance: normalized MSE = inf
loss: 0.9581372045911849; best overall distance: normalized MSE = inf
loss: 0.9581456018146128; best overall distance: normalized MSE = inf
loss: 0.9581540183629841; best overall distance: normalized MSE = inf
failed to find adversarial with const = 0.1
starting optimization with const = 1.0
loss: 9.597737312316895; best overall distance: normalized MSE = inf
loss: 9.590045246688533; best overall distance: normalized MSE = inf
loss: 9.58315831841901; best overall distance: normalized MSE = inf
loss: 9.576774153159931; best overall distance: normalized MSE = inf
loss: 9.570836105849594; best overall distance: normalized MSE = inf
loss: 9.565209284890443; best overall distance: normalized MSE = inf
loss: 9.560233407188207; best overall distance: normalized MSE = inf
loss: 9.555819170549512; best overall distance: normalized MSE = inf
loss: 9.55171289946884; best overall distance: normalized MSE = inf
loss: 9.548023348674178; best overall distance: normalized MSE = inf
loss: 9.544564060866833; best overall distance: normalized MSE = inf
loss: 9.541395206004381; best overall distance: normalized MSE = inf
loss: 9.538423873484135; best overall distance: normalized MSE = inf
loss: 9.535616844892502; best overall distance: normalized MSE = inf
loss: 9.532998647540808; best overall distance: normalized MSE = inf
loss: 9.530591610819101; best overall distance: normalized MSE = inf
loss: 9.52826914191246; best overall distance: normalized MSE = inf
loss: 9.526081711053848; best overall distance: normalized MSE = inf
loss: 9.523999262601137; best overall distance: normalized MSE = inf
loss: 9.522034890949726; best overall distance: normalized MSE = inf
loss: 9.520147431641817; best overall distance: normalized MSE = inf
loss: 9.518243622034788; best overall distance: normalized MSE = inf
loss: 9.516567159444094; best overall distance: normalized MSE = inf
loss: 9.514902010560036; best overall distance: normalized MSE = inf
loss: 9.513218596577644; best overall distance: normalized MSE = inf
loss: 9.511712450534105; best overall distance: normalized MSE = inf
loss: 9.510266158729792; best overall distance: normalized MSE = inf
loss: 9.50877146050334; best overall distance: normalized MSE = inf
loss: 9.50738763064146; best overall distance: normalized MSE = inf
loss: 9.506051421165466; best overall distance: normalized MSE = inf
loss: 9.504781007766724; best overall distance: normalized MSE = inf
loss: 9.503573849797249; best overall distance: normalized MSE = inf
loss: 9.502409845590591; best overall distance: normalized MSE = inf
loss: 9.501323983073235; best overall distance: normalized MSE = inf
loss: 9.500256069004536; best overall distance: normalized MSE = inf
loss: 9.499167025089264; best overall distance: normalized MSE = inf
loss: 9.49817830324173; best overall distance: normalized MSE = inf
loss: 9.497254446148872; best overall distance: normalized MSE = inf
loss: 9.496366158127785; best overall distance: normalized MSE = inf
loss: 9.495474517345428; best overall distance: normalized MSE = inf
loss: 9.494631290435791; best overall distance: normalized MSE = inf
loss: 9.49386240541935; best overall distance: normalized MSE = inf
loss: 9.493184946477413; best overall distance: normalized MSE = inf
loss: 9.492445424199104; best overall distance: normalized MSE = inf
loss: 9.491740263998508; best overall distance: normalized MSE = inf
loss: 9.49104431271553; best overall distance: normalized MSE = inf
loss: 9.490378193557262; best overall distance: normalized MSE = inf
loss: 9.489688441157341; best overall distance: normalized MSE = inf
loss: 9.489051595330238; best overall distance: normalized MSE = inf
loss: 9.488394603133202; best overall distance: normalized MSE = inf
loss: 9.487671628594398; best overall distance: normalized MSE = inf
loss: 9.487045727670193; best overall distance: normalized MSE = inf
loss: 9.486420080065727; best overall distance: normalized MSE = inf
loss: 9.485830821096897; best overall distance: normalized MSE = inf
loss: 9.485233709216118; best overall distance: normalized MSE = inf
loss: 9.484698452055454; best overall distance: normalized MSE = inf
loss: 9.48406022042036; best overall distance: normalized MSE = inf
loss: 9.48346871137619; best overall distance: normalized MSE = inf
loss: 9.482866518199444; best overall distance: normalized MSE = inf
loss: 9.48222105205059; best overall distance: normalized MSE = inf
loss: 9.481601670384407; best overall distance: normalized MSE = inf
loss: 9.480960085988045; best overall distance: normalized MSE = inf
loss: 9.48020326346159; best overall distance: normalized MSE = inf
loss: 9.479459799826145; best overall distance: normalized MSE = inf
loss: 9.478772833943367; best overall distance: normalized MSE = inf
loss: 9.478065080940723; best overall distance: normalized MSE = inf
loss: 9.477339565753937; best overall distance: normalized MSE = inf
loss: 9.476610854268074; best overall distance: normalized MSE = inf
loss: 9.476019069552422; best overall distance: normalized MSE = inf
loss: 9.47528424859047; best overall distance: normalized MSE = inf
loss: 9.474462911486626; best overall distance: normalized MSE = inf
loss: 9.473752990365028; best overall distance: normalized MSE = inf
loss: 9.473048813641071; best overall distance: normalized MSE = inf
loss: 9.47234533727169; best overall distance: normalized MSE = inf
loss: 9.471592202782631; best overall distance: normalized MSE = inf
loss: 9.470894649624825; best overall distance: normalized MSE = inf
loss: 9.470217861235142; best overall distance: normalized MSE = inf
loss: 9.469495669007301; best overall distance: normalized MSE = inf
loss: 9.468742795288563; best overall distance: normalized MSE = inf
loss: 9.46802319586277; best overall distance: normalized MSE = inf
loss: 9.467354282736778; best overall distance: normalized MSE = inf
loss: 9.466728903353214; best overall distance: normalized MSE = inf
loss: 9.466105379164219; best overall distance: normalized MSE = inf
loss: 9.465488255023956; best overall distance: normalized MSE = inf
loss: 9.464886039495468; best overall distance: normalized MSE = inf
loss: 9.464252650737762; best overall distance: normalized MSE = inf
loss: 9.463498704135418; best overall distance: normalized MSE = inf
loss: 9.46273735165596; best overall distance: normalized MSE = inf
loss: 9.461999453604221; best overall distance: normalized MSE = inf
loss: 9.461254701018333; best overall distance: normalized MSE = inf
loss: 9.460542485117912; best overall distance: normalized MSE = inf
loss: 9.459800206124783; best overall distance: normalized MSE = inf
loss: 9.4590063393116; best overall distance: normalized MSE = inf
loss: 9.458223208785057; best overall distance: normalized MSE = inf
loss: 9.457420013844967; best overall distance: normalized MSE = inf
loss: 9.456589125096798; best overall distance: normalized MSE = inf
loss: 9.455787621438503; best overall distance: normalized MSE = inf
loss: 9.45501497387886; best overall distance: normalized MSE = inf
loss: 9.454268015921116; best overall distance: normalized MSE = inf
loss: 9.45362851023674; best overall distance: normalized MSE = inf
loss: 9.452898159623146; best overall distance: normalized MSE = inf
loss: 9.452041380107403; best overall distance: normalized MSE = inf
loss: 9.451316148042679; best overall distance: normalized MSE = inf
loss: 9.450623273849487; best overall distance: normalized MSE = inf
loss: 9.449935488402843; best overall distance: normalized MSE = inf
loss: 9.449253663420677; best overall distance: normalized MSE = inf
loss: 9.448560208082199; best overall distance: normalized MSE = inf
loss: 9.447803422808647; best overall distance: normalized MSE = inf
loss: 9.447044551372528; best overall distance: normalized MSE = inf
loss: 9.44640600681305; best overall distance: normalized MSE = inf
loss: 9.445797175168991; best overall distance: normalized MSE = inf
loss: 9.44518792629242; best overall distance: normalized MSE = inf
loss: 9.44451156258583; best overall distance: normalized MSE = inf
loss: 9.443784177303314; best overall distance: normalized MSE = inf
loss: 9.443144768476486; best overall distance: normalized MSE = inf
loss: 9.44255405664444; best overall distance: normalized MSE = inf
loss: 9.441884189844131; best overall distance: normalized MSE = inf
loss: 9.441122204065323; best overall distance: normalized MSE = inf
/Users/limuyang/Nustore Files/First Half of Junior Year/John/torchdiffeq/fooling/ode_fooling.py
import argparse
import logging
import os

import foolbox
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

DOWNLOAD_MNIST = False
use_gray = False

parser = argparse.ArgumentParser()
parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')
parser.add_argument('--tol', type=float, default=1e-3)
parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])
parser.add_argument('--downsampling-method', type=str, default='res', choices=['conv', 'res'])
parser.add_argument('--nepochs', type=int, default=160)
parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])
parser.add_argument('--lr', type=float, default=0.1)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--continuing', type=eval, default=False, choices=[True, False])
parser.add_argument('--save', type=str, default='./experiment1')
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint


def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)


def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


def norm(dim):
    return nn.GroupNorm(min(32, dim), dim)


def my_show_transform(x, use_gray):
    x = (x + 1.0) / 2.0
    """Imshow for Tensor."""
    x = np.clip(x, 0, 1)
    if use_gray:
        plt.imshow(x, cmap='gray')
    else:
        plt.imshow(x)
    return x


class ResBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(ResBlock, self).__init__()
        self.norm1 = norm(inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.norm2 = norm(planes)
        self.conv2 = conv3x3(planes, planes)

    def forward(self, x):
        shortcut = x

        out = self.relu(self.norm1(x))

        if self.downsample is not None:
            shortcut = self.downsample(out)

        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)

        return out + shortcut


class ODEfunc(nn.Module):

    def __init__(self, dim):
        super(ODEfunc, self).__init__()
        self.norm1 = norm(dim)
        self.relu = nn.ReLU(inplace=True)
        self.conv1 = conv3x3(dim, dim)
        self.norm2 = norm(dim)
        self.conv2 = conv3x3(dim, dim)
        self.norm3 = norm(dim)
        self.nfe = 0

    def forward(self, t, x):
        self.nfe += 1
        out = self.norm1(x)
        out = self.relu(out)
        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.norm3(out)
        return out


class ODEBlock(nn.Module):

    def __init__(self, odefunc):
        super(ODEBlock, self).__init__()
        self.odefunc = odefunc
        self.integration_time = torch.tensor([0, 1]).float()

    def forward(self, x):
        self.integration_time = self.integration_time.type_as(x)
        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)
        return out[1]

    @property
    def nfe(self):
        return self.odefunc.nfe

    @nfe.setter
    def nfe(self, value):
        self.odefunc.nfe = value


class Flatten(nn.Module):

    def __init__(self):
        super(Flatten, self).__init__()

    def forward(self, x):
        shape = torch.prod(torch.tensor(x.shape[1:])).item()
        return x.view(-1, shape)


class RunningAverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self, momentum=0.99):
        self.momentum = momentum
        self.reset()

    def reset(self):
        self.val = None
        self.avg = 0

    def update(self, val):
        if self.val is None:
            self.avg = val
        else:
            self.avg = self.avg * self.momentum + val * (1 - self.momentum)
        self.val = val


def inf_generator(iterable):
    """Allows training with DataLoaders in a single infinite loop:
        for i, (x, y) in enumerate(inf_generator(train_loader)):
    """
    iterator = iterable.__iter__()
    while True:
        try:
            yield iterator.__next__()
        except StopIteration:
            iterator = iterable.__iter__()


def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):
    initial_learning_rate = args.lr * batch_size / batch_denom

    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]
    vals = [initial_learning_rate * decay for decay in decay_rates]

    def learning_rate_fn(itr):
        lt = [itr < b for b in boundaries] + [True]
        i = np.argmax(lt)
        return vals[i]

    return learning_rate_fn


def one_hot(x, K):
    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)


def accuracy(model, dataset_loader):
    total_correct = 0
    for x, y in dataset_loader:
        x = x.to(device)
        y = one_hot(np.array(y.numpy()), 10)

        target_class = np.argmax(y, axis=1)
        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)
        total_correct += np.sum(predicted_class == target_class)
    return total_correct / len(dataset_loader.dataset)


def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def makedirs(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):
    logger = logging.getLogger()
    if debug:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logger.setLevel(level)
    if saving:
        info_file_handler = logging.FileHandler(logpath, mode="a")
        info_file_handler.setLevel(level)
        logger.addHandler(info_file_handler)
    if displaying:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        logger.addHandler(console_handler)
    logger.info(filepath)
    with open(filepath, "r") as f:
        logger.info(f.read())

    for f in package_files:
        logger.info(f)
        with open(f, "r") as package_f:
            logger.info(package_f.read())

    return logger


if __name__ == '__main__':

    makedirs(args.save)
    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)

    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')

    is_odenet = args.network == 'odenet'

    if args.downsampling_method == 'conv':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
        ]
    elif args.downsampling_method == 'res':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
        ]

    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]
    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]

    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)

    # pay attention to this!! 
    SET_CONTINUE = True
    if args.continuing or SET_CONTINUE:
        model.load_state_dict(torch.load('model.pth', map_location='cpu')['state_dict'])

    mean = np.array([0.5])
    std = np.array([0.5])

    fmodel = foolbox.models.PyTorchModel(
        model, bounds=(-1, 1), num_classes=10, preprocessing=(mean, std))

    # get source image and label
    my_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])

    test_data = torchvision.datasets.MNIST(
        root='./mnist',
        train=False,
        download=DOWNLOAD_MNIST,
        transform=my_transform
    )

    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)

    for batch_idx, (data, target) in enumerate(test_loader):
        label = target.data.numpy()[0]
        print('label', label)
        image = data.squeeze(0).cpu().numpy()
        plt.subplot(1, 2, 1)
        my_show_transform(image.squeeze(), use_gray)
        predict = np.argmax(fmodel.predictions(image))
        print('predicted class', predict)

        method_name = 'CarliniWagnerL2Attack'
        save_path = os.path.join(r'log/result_pic', method_name)
        makedirs(save_path)

        attack = foolbox.attacks.CarliniWagnerL2Attack()  # (fmodel)

        criterion = foolbox.criteria.Misclassification()
        adversarial = foolbox.Adversarial(fmodel, criterion, image, np.array(label, dtype=np.int64),
                                          distance=foolbox.distances.MSE)
        attack(adversarial)
        adversarial = adversarial.image

        adversarial_predict = np.argmax(fmodel.predictions(adversarial))
        print('adversarial class', adversarial_predict)
        plt.subplot(1, 2, 2)

        if use_gray:
            plt.imshow(adversarial.squeeze(), cmap='gray')  #
        else:
            plt.imshow(adversarial.squeeze())  # , cmap ='gray'

        # plt.savefig(os.path.join(save_path, 'example.png'))
        plt.show()

        # with open(r'log/log.txt','a') as f:
        #   f.write(method_name + ' : ODE ' + str(predict) + ' -> ' + str(adversarial_predict)+ '\n')
        break

Namespace(adjoint=False, batch_size=128, continuing=False, data_aug=True, debug=False, downsampling_method='res', gpu=0, lr=0.1, nepochs=160, network='odenet', save='./experiment1', test_batch_size=1000, tol=0.001)
starting optimization with const = 0.01
loss: 0.09597737312316895; best overall distance: normalized MSE = inf
loss: 0.096139037408866; best overall distance: normalized MSE = inf
loss: 0.09598035954797524; best overall distance: normalized MSE = inf
loss: 0.09599980271304957; best overall distance: normalized MSE = inf
loss: 0.09605872517975513; best overall distance: normalized MSE = inf
loss: 0.09602851898045628; best overall distance: normalized MSE = inf
loss: 0.09597611666002194; best overall distance: normalized MSE = inf
loss: 0.0959661251304351; best overall distance: normalized MSE = inf
loss: 0.09599343282403425; best overall distance: normalized MSE = inf
loss: 0.09600933084264397; best overall distance: normalized MSE = inf
loss: 0.09599519763316494; best overall distance: normalized MSE = inf
loss: 0.09597146481391974; best overall distance: normalized MSE = inf
loss: 0.0959638041854123; best overall distance: normalized MSE = inf
loss: 0.09597371515825216; best overall distance: normalized MSE = inf
loss: 0.09598375761212083; best overall distance: normalized MSE = inf
loss: 0.0959818049443129; best overall distance: normalized MSE = inf
loss: 0.0959716346760979; best overall distance: normalized MSE = inf
loss: 0.09596438433160075; best overall distance: normalized MSE = inf
loss: 0.09596517646350548; best overall distance: normalized MSE = inf
loss: 0.09596959690417861; best overall distance: normalized MSE = inf
loss: 0.09597136749245692; best overall distance: normalized MSE = inf
loss: 0.09596874497758108; best overall distance: normalized MSE = inf
loss: 0.09596483815214014; best overall distance: normalized MSE = inf
loss: 0.09596298567434133; best overall distance: normalized MSE = inf
loss: 0.09596371030242154; best overall distance: normalized MSE = inf
loss: 0.09596489581024799; best overall distance: normalized MSE = inf
loss: 0.09596476714345045; best overall distance: normalized MSE = inf
loss: 0.09596352869994007; best overall distance: normalized MSE = inf
loss: 0.09596224875822372; best overall distance: normalized MSE = inf
loss: 0.09596170401920973; best overall distance: normalized MSE = inf
loss: 0.09596189184710965; best overall distance: normalized MSE = inf
loss: 0.09596213743803673; best overall distance: normalized MSE = inf
loss: 0.09596193848847179; best overall distance: normalized MSE = inf
loss: 0.09596132114937063; best overall distance: normalized MSE = inf
loss: 0.09596072851971257; best overall distance: normalized MSE = inf
loss: 0.09596044742749654; best overall distance: normalized MSE = inf
loss: 0.09596058783587069; best overall distance: normalized MSE = inf
loss: 0.09596069802777493; best overall distance: normalized MSE = inf
loss: 0.09596048133680597; best overall distance: normalized MSE = inf
loss: 0.09596006841602503; best overall distance: normalized MSE = inf
loss: 0.09595982359023765; best overall distance: normalized MSE = inf
loss: 0.09595982688617369; best overall distance: normalized MSE = inf
loss: 0.09595998127595522; best overall distance: normalized MSE = inf
loss: 0.09595986136708234; best overall distance: normalized MSE = inf
loss: 0.0959596113889711; best overall distance: normalized MSE = inf
loss: 0.09595945615656092; best overall distance: normalized MSE = inf
loss: 0.09595945438995841; best overall distance: normalized MSE = inf
loss: 0.09595950815302785; best overall distance: normalized MSE = inf
loss: 0.09595946927613114; best overall distance: normalized MSE = inf
loss: 0.09595928620299674; best overall distance: normalized MSE = inf
loss: 0.09595921523221478; best overall distance: normalized MSE = inf
loss: 0.09595921731408452; best overall distance: normalized MSE = inf
loss: 0.09595927504065913; best overall distance: normalized MSE = inf
loss: 0.09595920277773985; best overall distance: normalized MSE = inf
loss: 0.09595911520424125; best overall distance: normalized MSE = inf
loss: 0.09595904543733923; best overall distance: normalized MSE = inf
loss: 0.09595909566487536; best overall distance: normalized MSE = inf
loss: 0.09595913048295188; best overall distance: normalized MSE = inf
loss: 0.09595905567839509; best overall distance: normalized MSE = inf
loss: 0.09595900752538; best overall distance: normalized MSE = inf
loss: 0.09595899790539988; best overall distance: normalized MSE = inf
loss: 0.0959590433982521; best overall distance: normalized MSE = inf
loss: 0.09595902730972738; best overall distance: normalized MSE = inf
loss: 0.09595895721227862; best overall distance: normalized MSE = inf
loss: 0.09595892709388863; best overall distance: normalized MSE = inf
loss: 0.09595896080165403; best overall distance: normalized MSE = inf
loss: 0.09595895764272427; best overall distance: normalized MSE = inf
loss: 0.09595892209501472; best overall distance: normalized MSE = inf
loss: 0.09595892880366591; best overall distance: normalized MSE = inf
loss: 0.09595892589728465; best overall distance: normalized MSE = inf
loss: 0.0959589361923281; best overall distance: normalized MSE = inf
loss: 0.0959589305544796; best overall distance: normalized MSE = inf
loss: 0.09595889965828974; best overall distance: normalized MSE = inf
loss: 0.09595890393415175; best overall distance: normalized MSE = inf
loss: 0.09595890464901459; best overall distance: normalized MSE = inf
loss: 0.09595889662239643; best overall distance: normalized MSE = inf
loss: 0.09595889669260942; best overall distance: normalized MSE = inf
loss: 0.09595888843905413; best overall distance: normalized MSE = inf
loss: 0.09595888724419638; best overall distance: normalized MSE = inf
loss: 0.09595890183671145; best overall distance: normalized MSE = inf
loss: 0.09595887195850082; best overall distance: normalized MSE = inf
loss: 0.09595888017662219; best overall distance: normalized MSE = inf
loss: 0.09595890900061932; best overall distance: normalized MSE = inf
loss: 0.09595888494754036; best overall distance: normalized MSE = inf
loss: 0.09595887370698619; best overall distance: normalized MSE = inf
loss: 0.09595890849843272; best overall distance: normalized MSE = inf
loss: 0.095958867684094; best overall distance: normalized MSE = inf
loss: 0.09595888597439625; best overall distance: normalized MSE = inf
loss: 0.09595888299911166; best overall distance: normalized MSE = inf
loss: 0.09595887690069503; best overall distance: normalized MSE = inf
loss: 0.0959588785799133; best overall distance: normalized MSE = inf
loss: 0.09595887045230483; best overall distance: normalized MSE = inf
loss: 0.09595886439172319; best overall distance: normalized MSE = inf
loss: 0.09595885747068678; best overall distance: normalized MSE = inf
loss: 0.09595887543451681; best overall distance: normalized MSE = inf
loss: 0.09595886811366654; best overall distance: normalized MSE = inf
loss: 0.0959588687352516; best overall distance: normalized MSE = inf
loss: 0.09595887282208423; best overall distance: normalized MSE = inf
loss: 0.0959588747448288; best overall distance: normalized MSE = inf
loss: 0.09595885883805749; best overall distance: normalized MSE = inf
loss: 0.09595887532952474; best overall distance: normalized MSE = inf
loss: 0.09595888066323824; best overall distance: normalized MSE = inf
loss: 0.09595887390198186; best overall distance: normalized MSE = inf
loss: 0.0959588668642391; best overall distance: normalized MSE = inf
loss: 0.09595886401089956; best overall distance: normalized MSE = inf
loss: 0.0959588526999869; best overall distance: normalized MSE = inf
loss: 0.09595888552510587; best overall distance: normalized MSE = inf
loss: 0.09595886196490028; best overall distance: normalized MSE = inf
loss: 0.09595887163966836; best overall distance: normalized MSE = inf
loss: 0.09595886879200408; best overall distance: normalized MSE = inf
loss: 0.09595888287367416; best overall distance: normalized MSE = inf
loss: 0.0959588479451486; best overall distance: normalized MSE = inf
loss: 0.09595886682924175; best overall distance: normalized MSE = inf
loss: 0.09595887152114302; best overall distance: normalized MSE = inf
loss: 0.09595886413153494; best overall distance: normalized MSE = inf
loss: 0.09595886638664525; best overall distance: normalized MSE = inf
loss: 0.09595886722017895; best overall distance: normalized MSE = inf
loss: 0.09595884973918146; best overall distance: normalized MSE = inf
loss: 0.09595887836097973; best overall distance: normalized MSE = inf
loss: 0.09595886682880518; best overall distance: normalized MSE = inf
loss: 0.09595888551419193; best overall distance: normalized MSE = inf
loss: 0.09595888096060662; best overall distance: normalized MSE = inf
loss: 0.09595885874550732; best overall distance: normalized MSE = inf
loss: 0.09595886308037735; best overall distance: normalized MSE = inf
loss: 0.0959588710116077; best overall distance: normalized MSE = inf
loss: 0.09595887931369362; best overall distance: normalized MSE = inf
loss: 0.09595886520946806; best overall distance: normalized MSE = inf
loss: 0.09595886329545465; best overall distance: normalized MSE = inf
loss: 0.09595885279966751; best overall distance: normalized MSE = inf
loss: 0.09595887780284101; best overall distance: normalized MSE = inf
loss: 0.09595885347473086; best overall distance: normalized MSE = inf
loss: 0.09595887213392416; best overall distance: normalized MSE = inf
loss: 0.09595887104820577; best overall distance: normalized MSE = inf
loss: 0.09595886419789168; best overall distance: normalized MSE = inf
loss: 0.09595885914270184; best overall distance: normalized MSE = inf
loss: 0.09595885885144526; best overall distance: normalized MSE = inf
loss: 0.0959588607486512; best overall distance: normalized MSE = inf
loss: 0.09595886085982784; best overall distance: normalized MSE = inf
loss: 0.0959588594230445; best overall distance: normalized MSE = inf
loss: 0.09595886932176655; best overall distance: normalized MSE = inf
loss: 0.0959588728503877; best overall distance: normalized MSE = inf
loss: 0.09595884803980881; best overall distance: normalized MSE = inf
loss: 0.09595885699629435; best overall distance: normalized MSE = inf
loss: 0.09595886099443306; best overall distance: normalized MSE = inf
loss: 0.09595885510658264; best overall distance: normalized MSE = inf
loss: 0.0959588643340976; best overall distance: normalized MSE = inf
loss: 0.09595886063791113; best overall distance: normalized MSE = inf
loss: 0.09595887656090782; best overall distance: normalized MSE = inf
loss: 0.09595885754199117; best overall distance: normalized MSE = inf
loss: 0.09595887004732503; best overall distance: normalized MSE = inf
loss: 0.0959588446021371; best overall distance: normalized MSE = inf
loss: 0.09595886347189662; best overall distance: normalized MSE = inf
loss: 0.09595886024682841; best overall distance: normalized MSE = inf
loss: 0.09595883784277248; best overall distance: normalized MSE = inf
loss: 0.09595887549861801; best overall distance: normalized MSE = inf
loss: 0.09595885900809663; best overall distance: normalized MSE = inf
loss: 0.09595888077368728; best overall distance: normalized MSE = inf
loss: 0.09595887208823115; best overall distance: normalized MSE = inf
loss: 0.09595886066701496; best overall distance: normalized MSE = inf
loss: 0.09595887698655134; best overall distance: normalized MSE = inf
loss: 0.09595885654518498; best overall distance: normalized MSE = inf
loss: 0.0959588576729584; best overall distance: normalized MSE = inf
loss: 0.09595887890376617; best overall distance: normalized MSE = inf
loss: 0.09595886161470844; best overall distance: normalized MSE = inf
loss: 0.09595887109870091; best overall distance: normalized MSE = inf
loss: 0.09595886948161933; best overall distance: normalized MSE = inf
loss: 0.0959588583787263; best overall distance: normalized MSE = inf
loss: 0.09595887718664017; best overall distance: normalized MSE = inf
loss: 0.09595885894806998; best overall distance: normalized MSE = inf
loss: 0.09595886023773346; best overall distance: normalized MSE = inf
loss: 0.0959588611927029; best overall distance: normalized MSE = inf
loss: 0.0959588608489139; best overall distance: normalized MSE = inf
loss: 0.09595886931791028; best overall distance: normalized MSE = inf
loss: 0.0959588590481144; best overall distance: normalized MSE = inf
loss: 0.09595887856179616; best overall distance: normalized MSE = inf
loss: 0.09595887006551493; best overall distance: normalized MSE = inf
loss: 0.09595885184513464; best overall distance: normalized MSE = inf
loss: 0.09595888025345631; best overall distance: normalized MSE = inf
loss: 0.0959588696762512; best overall distance: normalized MSE = inf
loss: 0.09595885929185898; best overall distance: normalized MSE = inf
loss: 0.09595885955015547; best overall distance: normalized MSE = inf
loss: 0.0959588701037137; best overall distance: normalized MSE = inf
loss: 0.09595885203612853; best overall distance: normalized MSE = inf
loss: 0.09595885177055608; best overall distance: normalized MSE = inf
loss: 0.095958860659739; best overall distance: normalized MSE = inf
loss: 0.09595887896924979; best overall distance: normalized MSE = inf
loss: 0.09595885998853192; best overall distance: normalized MSE = inf
loss: 0.0959588701055327; best overall distance: normalized MSE = inf
loss: 0.09595887074399798; best overall distance: normalized MSE = inf
loss: 0.09595888009702322; best overall distance: normalized MSE = inf
loss: 0.09595887005460099; best overall distance: normalized MSE = inf
loss: 0.0959588698472362; best overall distance: normalized MSE = inf
loss: 0.09595886029230315; best overall distance: normalized MSE = inf
loss: 0.09595887028197467; best overall distance: normalized MSE = inf
loss: 0.0959588706366776; best overall distance: normalized MSE = inf
loss: 0.09595887096045772; best overall distance: normalized MSE = inf
loss: 0.09595887032381142; best overall distance: normalized MSE = inf
loss: 0.09595886991271982; best overall distance: normalized MSE = inf
loss: 0.09595887925665011; best overall distance: normalized MSE = inf
loss: 0.09595887985327864; best overall distance: normalized MSE = inf
loss: 0.09595888023162844; best overall distance: normalized MSE = inf
failed to find adversarial with const = 0.01
starting optimization with const = 0.1
loss: 0.9597737312316895; best overall distance: normalized MSE = inf
loss: 0.959222050034441; best overall distance: normalized MSE = inf
loss: 0.9589682152494788; best overall distance: normalized MSE = inf
loss: 0.9588687780778855; best overall distance: normalized MSE = inf
loss: 0.9588360693771393; best overall distance: normalized MSE = inf
loss: 0.9587986775208265; best overall distance: normalized MSE = inf
loss: 0.9587561524705962; best overall distance: normalized MSE = inf
loss: 0.9587145067518578; best overall distance: normalized MSE = inf
loss: 0.9586739638820291; best overall distance: normalized MSE = inf
loss: 0.9586394489509985; best overall distance: normalized MSE = inf
loss: 0.9586116553051398; best overall distance: normalized MSE = inf
loss: 0.9585966030135751; best overall distance: normalized MSE = inf
loss: 0.9585839154198766; best overall distance: normalized MSE = inf
loss: 0.9585650303633884; best overall distance: normalized MSE = inf
loss: 0.958542990568094; best overall distance: normalized MSE = inf
loss: 0.9585216373670846; best overall distance: normalized MSE = inf
loss: 0.9585049801040442; best overall distance: normalized MSE = inf
loss: 0.9584988377289847; best overall distance: normalized MSE = inf
loss: 0.9584921436849982; best overall distance: normalized MSE = inf
loss: 0.9584795661969111; best overall distance: normalized MSE = inf
loss: 0.9584806324215607; best overall distance: normalized MSE = inf
loss: 0.9584700342733413; best overall distance: normalized MSE = inf
loss: 0.9584496644325555; best overall distance: normalized MSE = inf
loss: 0.9584406605456025; best overall distance: normalized MSE = inf
loss: 0.958435007557273; best overall distance: normalized MSE = inf
loss: 0.9584229291416705; best overall distance: normalized MSE = inf
loss: 0.9584089328069241; best overall distance: normalized MSE = inf
loss: 0.9584043422481046; best overall distance: normalized MSE = inf
loss: 0.9583940495271236; best overall distance: normalized MSE = inf
loss: 0.9583870633505285; best overall distance: normalized MSE = inf
loss: 0.9583850007737056; best overall distance: normalized MSE = inf
loss: 0.9583748967386783; best overall distance: normalized MSE = inf
loss: 0.9583696933928878; best overall distance: normalized MSE = inf
loss: 0.9583656126400456; best overall distance: normalized MSE = inf
loss: 0.9583575583528727; best overall distance: normalized MSE = inf
loss: 0.9583533045370132; best overall distance: normalized MSE = inf
loss: 0.9583495364524425; best overall distance: normalized MSE = inf
loss: 0.9583424271782861; best overall distance: normalized MSE = inf
loss: 0.9583383619319648; best overall distance: normalized MSE = inf
loss: 0.9583304431289434; best overall distance: normalized MSE = inf
loss: 0.9583274438744411; best overall distance: normalized MSE = inf
loss: 0.9583203675225378; best overall distance: normalized MSE = inf
loss: 0.9583175910403953; best overall distance: normalized MSE = inf
loss: 0.9583165786694736; best overall distance: normalized MSE = inf
loss: 0.9583098547998816; best overall distance: normalized MSE = inf
loss: 0.9583019936922939; best overall distance: normalized MSE = inf
loss: 0.9582977327052504; best overall distance: normalized MSE = inf
loss: 0.9582976806210355; best overall distance: normalized MSE = inf
loss: 0.9582910362165422; best overall distance: normalized MSE = inf
loss: 0.958286983310245; best overall distance: normalized MSE = inf
loss: 0.9582859937101603; best overall distance: normalized MSE = inf
loss: 0.9582790488144384; best overall distance: normalized MSE = inf
loss: 0.9582763428799809; best overall distance: normalized MSE = inf
loss: 0.9582759964512662; best overall distance: normalized MSE = inf
loss: 0.9582725587533787; best overall distance: normalized MSE = inf
loss: 0.9582654464058579; best overall distance: normalized MSE = inf
loss: 0.9582731297239662; best overall distance: normalized MSE = inf
loss: 0.9582690654788166; best overall distance: normalized MSE = inf
loss: 0.9582570235943422; best overall distance: normalized MSE = inf
loss: 0.9582570887636394; best overall distance: normalized MSE = inf
loss: 0.9582519020652399; best overall distance: normalized MSE = inf
loss: 0.9582539383787663; best overall distance: normalized MSE = inf
loss: 0.9582489572931081; best overall distance: normalized MSE = inf
loss: 0.9582472580950707; best overall distance: normalized MSE = inf
loss: 0.9582467010710389; best overall distance: normalized MSE = inf
loss: 0.95824109246023; best overall distance: normalized MSE = inf
loss: 0.9582410637987778; best overall distance: normalized MSE = inf
loss: 0.9582384058041499; best overall distance: normalized MSE = inf
loss: 0.9582333974307403; best overall distance: normalized MSE = inf
loss: 0.9582332527730615; best overall distance: normalized MSE = inf
loss: 0.9582276666769758; best overall distance: normalized MSE = inf
loss: 0.9582320562331006; best overall distance: normalized MSE = inf
loss: 0.958228138415143; best overall distance: normalized MSE = inf
loss: 0.9582246410660447; best overall distance: normalized MSE = inf
loss: 0.9582258893642575; best overall distance: normalized MSE = inf
loss: 0.9582209535408766; best overall distance: normalized MSE = inf
loss: 0.958218220830895; best overall distance: normalized MSE = inf
loss: 0.9582151747774333; best overall distance: normalized MSE = inf
loss: 0.9582170934416354; best overall distance: normalized MSE = inf
loss: 0.9582178900483996; best overall distance: normalized MSE = inf
loss: 0.9582123449305073; best overall distance: normalized MSE = inf
loss: 0.9582113922107965; best overall distance: normalized MSE = inf
loss: 0.9582084211986512; best overall distance: normalized MSE = inf
loss: 0.958208703971468; best overall distance: normalized MSE = inf
loss: 0.9582105348818004; best overall distance: normalized MSE = inf
loss: 0.9582060326356441; best overall distance: normalized MSE = inf
loss: 0.9582009055186064; best overall distance: normalized MSE = inf
loss: 0.9581989371683449; best overall distance: normalized MSE = inf
loss: 0.9582023827824742; best overall distance: normalized MSE = inf
loss: 0.9582033949904144; best overall distance: normalized MSE = inf
loss: 0.9581983955344185; best overall distance: normalized MSE = inf
loss: 0.9581968978978694; best overall distance: normalized MSE = inf
loss: 0.9581938187824562; best overall distance: normalized MSE = inf
loss: 0.9581972585525365; best overall distance: normalized MSE = inf
loss: 0.9581989596597851; best overall distance: normalized MSE = inf
loss: 0.9581945373909548; best overall distance: normalized MSE = inf
loss: 0.9581883862614632; best overall distance: normalized MSE = inf
loss: 0.9581862872932106; best overall distance: normalized MSE = inf
loss: 0.9581923454999924; best overall distance: normalized MSE = inf
loss: 0.9581936468835921; best overall distance: normalized MSE = inf
loss: 0.9581889514345676; best overall distance: normalized MSE = inf
loss: 0.958185234060511; best overall distance: normalized MSE = inf
loss: 0.9581827521324158; best overall distance: normalized MSE = inf
loss: 0.9581877885153518; best overall distance: normalized MSE = inf
loss: 0.9581904554041103; best overall distance: normalized MSE = inf
loss: 0.958186522172764; best overall distance: normalized MSE = inf
loss: 0.9581782777793706; best overall distance: normalized MSE = inf
loss: 0.9581949686165899; best overall distance: normalized MSE = inf
loss: 0.9581962375435978; best overall distance: normalized MSE = inf
loss: 0.9581833080388606; best overall distance: normalized MSE = inf
loss: 0.9581853511277587; best overall distance: normalized MSE = inf
loss: 0.9581930745393038; best overall distance: normalized MSE = inf
loss: 0.9581892809597776; best overall distance: normalized MSE = inf
loss: 0.9581802581902594; best overall distance: normalized MSE = inf
loss: 0.9581803828943521; best overall distance: normalized MSE = inf
loss: 0.9581819558050484; best overall distance: normalized MSE = inf
loss: 0.9581715380772948; best overall distance: normalized MSE = inf
loss: 0.9581726816948504; best overall distance: normalized MSE = inf
loss: 0.958171128272079; best overall distance: normalized MSE = inf
loss: 0.9581722009461373; best overall distance: normalized MSE = inf
loss: 0.9581698995316401; best overall distance: normalized MSE = inf
loss: 0.9581735966261477; best overall distance: normalized MSE = inf
loss: 0.9581691877916456; best overall distance: normalized MSE = inf
loss: 0.9581744679016992; best overall distance: normalized MSE = inf
loss: 0.9581781971734018; best overall distance: normalized MSE = inf
loss: 0.9581741829402746; best overall distance: normalized MSE = inf
loss: 0.9581655121408403; best overall distance: normalized MSE = inf
loss: 0.9581808654125781; best overall distance: normalized MSE = inf
loss: 0.9581824335735292; best overall distance: normalized MSE = inf
loss: 0.9581696352455765; best overall distance: normalized MSE = inf
loss: 0.958172644628212; best overall distance: normalized MSE = inf
loss: 0.9581807919079438; best overall distance: normalized MSE = inf
loss: 0.9581766563467682; best overall distance: normalized MSE = inf
loss: 0.9581671528518201; best overall distance: normalized MSE = inf
loss: 0.9581707987003029; best overall distance: normalized MSE = inf
loss: 0.9581732634687796; best overall distance: normalized MSE = inf
loss: 0.9581602623919026; best overall distance: normalized MSE = inf
loss: 0.9581734109669924; best overall distance: normalized MSE = inf
loss: 0.9581818855600432; best overall distance: normalized MSE = inf
loss: 0.9581774836871774; best overall distance: normalized MSE = inf
loss: 0.9581666700541973; best overall distance: normalized MSE = inf
loss: 0.9581636309623719; best overall distance: normalized MSE = inf
loss: 0.958167400979437; best overall distance: normalized MSE = inf
loss: 0.9581557325553149; best overall distance: normalized MSE = inf
loss: 0.958169508096762; best overall distance: normalized MSE = inf
loss: 0.9581776396371424; best overall distance: normalized MSE = inf
loss: 0.9581735395593569; best overall distance: normalized MSE = inf
loss: 0.9581624273676426; best overall distance: normalized MSE = inf
loss: 0.9581606137333438; best overall distance: normalized MSE = inf
loss: 0.9581649348838255; best overall distance: normalized MSE = inf
loss: 0.9581534988246858; best overall distance: normalized MSE = inf
loss: 0.9581655310932548; best overall distance: normalized MSE = inf
loss: 0.9581730919424445; best overall distance: normalized MSE = inf
loss: 0.9581697449088097; best overall distance: normalized MSE = inf
loss: 0.9581584680825472; best overall distance: normalized MSE = inf
loss: 0.9581580507569015; best overall distance: normalized MSE = inf
loss: 0.9581624841317535; best overall distance: normalized MSE = inf
loss: 0.95815085824579; best overall distance: normalized MSE = inf
loss: 0.9581620653858409; best overall distance: normalized MSE = inf
loss: 0.9581701932474971; best overall distance: normalized MSE = inf
loss: 0.9581665933597834; best overall distance: normalized MSE = inf
loss: 0.9581557917874307; best overall distance: normalized MSE = inf
loss: 0.9581533864140511; best overall distance: normalized MSE = inf
loss: 0.9581574882380665; best overall distance: normalized MSE = inf
loss: 0.9581460485002027; best overall distance: normalized MSE = inf
loss: 0.9581600054632873; best overall distance: normalized MSE = inf
loss: 0.9581682673888281; best overall distance: normalized MSE = inf
loss: 0.9581643779063598; best overall distance: normalized MSE = inf
loss: 0.9581537183374167; best overall distance: normalized MSE = inf
loss: 0.9581499819178134; best overall distance: normalized MSE = inf
loss: 0.9581536320969463; best overall distance: normalized MSE = inf
loss: 0.9581432833801955; best overall distance: normalized MSE = inf
loss: 0.9581442530965433; best overall distance: normalized MSE = inf
loss: 0.9581450167577714; best overall distance: normalized MSE = inf
loss: 0.9581442174036057; best overall distance: normalized MSE = inf
loss: 0.9581421990413219; best overall distance: normalized MSE = inf
loss: 0.9581495588412509; best overall distance: normalized MSE = inf
loss: 0.9581453896127642; best overall distance: normalized MSE = inf
loss: 0.9581473607569934; best overall distance: normalized MSE = inf
loss: 0.9581508373841644; best overall distance: normalized MSE = inf
loss: 0.9581479051616043; best overall distance: normalized MSE = inf
loss: 0.9581392244435847; best overall distance: normalized MSE = inf
loss: 0.9581569652538747; best overall distance: normalized MSE = inf
loss: 0.9581572647904978; best overall distance: normalized MSE = inf
loss: 0.9581430653808639; best overall distance: normalized MSE = inf
loss: 0.9581510890740902; best overall distance: normalized MSE = inf
loss: 0.9581608898472042; best overall distance: normalized MSE = inf
loss: 0.9581573093077168; best overall distance: normalized MSE = inf
loss: 0.9581463174894452; best overall distance: normalized MSE = inf
loss: 0.9581445473711938; best overall distance: normalized MSE = inf
loss: 0.9581488054711372; best overall distance: normalized MSE = inf
loss: 0.9581368018407375; best overall distance: normalized MSE = inf
loss: 0.9581501972395927; best overall distance: normalized MSE = inf
loss: 0.9581590360496194; best overall distance: normalized MSE = inf
loss: 0.9581552790710703; best overall distance: normalized MSE = inf
loss: 0.9581432458013297; best overall distance: normalized MSE = inf
loss: 0.958143249922432; best overall distance: normalized MSE = inf
loss: 0.9581487071700394; best overall distance: normalized MSE = inf
loss: 0.9581372045911849; best overall distance: normalized MSE = inf
loss: 0.9581456018146128; best overall distance: normalized MSE = inf
loss: 0.9581540183629841; best overall distance: normalized MSE = inf
failed to find adversarial with const = 0.1
starting optimization with const = 1.0
loss: 9.597737312316895; best overall distance: normalized MSE = inf
loss: 9.590045246688533; best overall distance: normalized MSE = inf
loss: 9.58315831841901; best overall distance: normalized MSE = inf
loss: 9.576774153159931; best overall distance: normalized MSE = inf
loss: 9.570836105849594; best overall distance: normalized MSE = inf
loss: 9.565209284890443; best overall distance: normalized MSE = inf
loss: 9.560233407188207; best overall distance: normalized MSE = inf
loss: 9.555819170549512; best overall distance: normalized MSE = inf
loss: 9.55171289946884; best overall distance: normalized MSE = inf
loss: 9.548023348674178; best overall distance: normalized MSE = inf
loss: 9.544564060866833; best overall distance: normalized MSE = inf
loss: 9.541395206004381; best overall distance: normalized MSE = inf
loss: 9.538423873484135; best overall distance: normalized MSE = inf
loss: 9.535616844892502; best overall distance: normalized MSE = inf
loss: 9.532998647540808; best overall distance: normalized MSE = inf
loss: 9.530591610819101; best overall distance: normalized MSE = inf
loss: 9.52826914191246; best overall distance: normalized MSE = inf
loss: 9.526081711053848; best overall distance: normalized MSE = inf
loss: 9.523999262601137; best overall distance: normalized MSE = inf
loss: 9.522034890949726; best overall distance: normalized MSE = inf
loss: 9.520147431641817; best overall distance: normalized MSE = inf
loss: 9.518243622034788; best overall distance: normalized MSE = inf
loss: 9.516567159444094; best overall distance: normalized MSE = inf
loss: 9.514902010560036; best overall distance: normalized MSE = inf
loss: 9.513218596577644; best overall distance: normalized MSE = inf
loss: 9.511712450534105; best overall distance: normalized MSE = inf
loss: 9.510266158729792; best overall distance: normalized MSE = inf
loss: 9.50877146050334; best overall distance: normalized MSE = inf
loss: 9.50738763064146; best overall distance: normalized MSE = inf
loss: 9.506051421165466; best overall distance: normalized MSE = inf
loss: 9.504781007766724; best overall distance: normalized MSE = inf
loss: 9.503573849797249; best overall distance: normalized MSE = inf
loss: 9.502409845590591; best overall distance: normalized MSE = inf
loss: 9.501323983073235; best overall distance: normalized MSE = inf
loss: 9.500256069004536; best overall distance: normalized MSE = inf
loss: 9.499167025089264; best overall distance: normalized MSE = inf
loss: 9.49817830324173; best overall distance: normalized MSE = inf
loss: 9.497254446148872; best overall distance: normalized MSE = inf
loss: 9.496366158127785; best overall distance: normalized MSE = inf
loss: 9.495474517345428; best overall distance: normalized MSE = inf
loss: 9.494631290435791; best overall distance: normalized MSE = inf
loss: 9.49386240541935; best overall distance: normalized MSE = inf
loss: 9.493184946477413; best overall distance: normalized MSE = inf
loss: 9.492445424199104; best overall distance: normalized MSE = inf
loss: 9.491740263998508; best overall distance: normalized MSE = inf
loss: 9.49104431271553; best overall distance: normalized MSE = inf
loss: 9.490378193557262; best overall distance: normalized MSE = inf
loss: 9.489688441157341; best overall distance: normalized MSE = inf
loss: 9.489051595330238; best overall distance: normalized MSE = inf
loss: 9.488394603133202; best overall distance: normalized MSE = inf
loss: 9.487671628594398; best overall distance: normalized MSE = inf
loss: 9.487045727670193; best overall distance: normalized MSE = inf
loss: 9.486420080065727; best overall distance: normalized MSE = inf
loss: 9.485830821096897; best overall distance: normalized MSE = inf
loss: 9.485233709216118; best overall distance: normalized MSE = inf
loss: 9.484698452055454; best overall distance: normalized MSE = inf
loss: 9.48406022042036; best overall distance: normalized MSE = inf
loss: 9.48346871137619; best overall distance: normalized MSE = inf
loss: 9.482866518199444; best overall distance: normalized MSE = inf
loss: 9.48222105205059; best overall distance: normalized MSE = inf
loss: 9.481601670384407; best overall distance: normalized MSE = inf
loss: 9.480960085988045; best overall distance: normalized MSE = inf
loss: 9.48020326346159; best overall distance: normalized MSE = inf
loss: 9.479459799826145; best overall distance: normalized MSE = inf
loss: 9.478772833943367; best overall distance: normalized MSE = inf
loss: 9.478065080940723; best overall distance: normalized MSE = inf
loss: 9.477339565753937; best overall distance: normalized MSE = inf
loss: 9.476610854268074; best overall distance: normalized MSE = inf
loss: 9.476019069552422; best overall distance: normalized MSE = inf
loss: 9.47528424859047; best overall distance: normalized MSE = inf
loss: 9.474462911486626; best overall distance: normalized MSE = inf
loss: 9.473752990365028; best overall distance: normalized MSE = inf
loss: 9.473048813641071; best overall distance: normalized MSE = inf
loss: 9.47234533727169; best overall distance: normalized MSE = inf
loss: 9.471592202782631; best overall distance: normalized MSE = inf
loss: 9.470894649624825; best overall distance: normalized MSE = inf
loss: 9.470217861235142; best overall distance: normalized MSE = inf
loss: 9.469495669007301; best overall distance: normalized MSE = inf
loss: 9.468742795288563; best overall distance: normalized MSE = inf
loss: 9.46802319586277; best overall distance: normalized MSE = inf
loss: 9.467354282736778; best overall distance: normalized MSE = inf
loss: 9.466728903353214; best overall distance: normalized MSE = inf
loss: 9.466105379164219; best overall distance: normalized MSE = inf
loss: 9.465488255023956; best overall distance: normalized MSE = inf
loss: 9.464886039495468; best overall distance: normalized MSE = inf
loss: 9.464252650737762; best overall distance: normalized MSE = inf
loss: 9.463498704135418; best overall distance: normalized MSE = inf
loss: 9.46273735165596; best overall distance: normalized MSE = inf
loss: 9.461999453604221; best overall distance: normalized MSE = inf
loss: 9.461254701018333; best overall distance: normalized MSE = inf
loss: 9.460542485117912; best overall distance: normalized MSE = inf
loss: 9.459800206124783; best overall distance: normalized MSE = inf
loss: 9.4590063393116; best overall distance: normalized MSE = inf
loss: 9.458223208785057; best overall distance: normalized MSE = inf
loss: 9.457420013844967; best overall distance: normalized MSE = inf
loss: 9.456589125096798; best overall distance: normalized MSE = inf
loss: 9.455787621438503; best overall distance: normalized MSE = inf
loss: 9.45501497387886; best overall distance: normalized MSE = inf
loss: 9.454268015921116; best overall distance: normalized MSE = inf
loss: 9.45362851023674; best overall distance: normalized MSE = inf
loss: 9.452898159623146; best overall distance: normalized MSE = inf
loss: 9.452041380107403; best overall distance: normalized MSE = inf
loss: 9.451316148042679; best overall distance: normalized MSE = inf
loss: 9.450623273849487; best overall distance: normalized MSE = inf
loss: 9.449935488402843; best overall distance: normalized MSE = inf
loss: 9.449253663420677; best overall distance: normalized MSE = inf
loss: 9.448560208082199; best overall distance: normalized MSE = inf
loss: 9.447803422808647; best overall distance: normalized MSE = inf
loss: 9.447044551372528; best overall distance: normalized MSE = inf
loss: 9.44640600681305; best overall distance: normalized MSE = inf
loss: 9.445797175168991; best overall distance: normalized MSE = inf
loss: 9.44518792629242; best overall distance: normalized MSE = inf
loss: 9.44451156258583; best overall distance: normalized MSE = inf
loss: 9.443784177303314; best overall distance: normalized MSE = inf
loss: 9.443144768476486; best overall distance: normalized MSE = inf
loss: 9.44255405664444; best overall distance: normalized MSE = inf
loss: 9.441884189844131; best overall distance: normalized MSE = inf
loss: 9.441122204065323; best overall distance: normalized MSE = inf
loss: 9.44057759642601; best overall distance: normalized MSE = inf
loss: 9.439956173300743; best overall distance: normalized MSE = inf
loss: 9.439280778169632; best overall distance: normalized MSE = inf
loss: 9.438546299934387; best overall distance: normalized MSE = inf
loss: 9.437881380319595; best overall distance: normalized MSE = inf
loss: 9.43724673986435; best overall distance: normalized MSE = inf
loss: 9.436719357967377; best overall distance: normalized MSE = inf
loss: 9.436326175928116; best overall distance: normalized MSE = inf
loss: 9.435824871063232; best overall distance: normalized MSE = inf
loss: 9.43530547618866; best overall distance: normalized MSE = inf
loss: 9.434839069843292; best overall distance: normalized MSE = inf
loss: 9.434350192546844; best overall distance: normalized MSE = inf
loss: 9.43383403122425; best overall distance: normalized MSE = inf
loss: 9.433316051959991; best overall distance: normalized MSE = inf
loss: 9.432726621627808; best overall distance: normalized MSE = inf
loss: 9.432279124855995; best overall distance: normalized MSE = inf
loss: 9.431904092431068; best overall distance: normalized MSE = inf
loss: 9.431459784507751; best overall distance: normalized MSE = inf
loss: 9.430967554450035; best overall distance: normalized MSE = inf
loss: 9.430413201451302; best overall distance: normalized MSE = inf
loss: 9.429907500743866; best overall distance: normalized MSE = inf
loss: 9.429490208625793; best overall distance: normalized MSE = inf
loss: 9.429054081439972; best overall distance: normalized MSE = inf
loss: 9.428564622998238; best overall distance: normalized MSE = inf
loss: 9.42804080247879; best overall distance: normalized MSE = inf
loss: 9.42756700515747; best overall distance: normalized MSE = inf
loss: 9.427111312747002; best overall distance: normalized MSE = inf
loss: 9.426661729812622; best overall distance: normalized MSE = inf
loss: 9.426215797662735; best overall distance: normalized MSE = inf
loss: 9.425730258226395; best overall distance: normalized MSE = inf
loss: 9.42532317340374; best overall distance: normalized MSE = inf
loss: 9.424942031502724; best overall distance: normalized MSE = inf
loss: 9.42454394698143; best overall distance: normalized MSE = inf
loss: 9.42414753139019; best overall distance: normalized MSE = inf
loss: 9.423734992742538; best overall distance: normalized MSE = inf
loss: 9.423317268490791; best overall distance: normalized MSE = inf
loss: 9.422914370894432; best overall distance: normalized MSE = inf
loss: 9.42250905930996; best overall distance: normalized MSE = inf
loss: 9.42210966348648; best overall distance: normalized MSE = inf
loss: 9.421707466244698; best overall distance: normalized MSE = inf
loss: 9.421237498521805; best overall distance: normalized MSE = inf
loss: 9.42077124118805; best overall distance: normalized MSE = inf
loss: 9.420202672481537; best overall distance: normalized MSE = inf
loss: 9.419603511691093; best overall distance: normalized MSE = inf
loss: 9.418859735131264; best overall distance: normalized MSE = inf
loss: 9.418877601623535; best overall distance: normalized MSE = inf
loss: 9.417900949716568; best overall distance: normalized MSE = inf
loss: 9.417671367526054; best overall distance: normalized MSE = inf
loss: 9.417382255196571; best overall distance: normalized MSE = inf
loss: 9.417141437530518; best overall distance: normalized MSE = inf
loss: 9.416818529367447; best overall distance: normalized MSE = inf
loss: 9.41647818684578; best overall distance: normalized MSE = inf
loss: 9.416073083877563; best overall distance: normalized MSE = inf
loss: 9.415636777877808; best overall distance: normalized MSE = inf
loss: 9.41525612771511; best overall distance: normalized MSE = inf
loss: 9.41477757692337; best overall distance: normalized MSE = inf
loss: 9.414292514324188; best overall distance: normalized MSE = inf
loss: 9.413804352283478; best overall distance: normalized MSE = inf
loss: 9.413336545228958; best overall distance: normalized MSE = inf
loss: 9.412902384996414; best overall distance: normalized MSE = inf
loss: 9.41244849562645; best overall distance: normalized MSE = inf
loss: 9.412047132849693; best overall distance: normalized MSE = inf
loss: 9.411654323339462; best overall distance: normalized MSE = inf
loss: 9.411273539066315; best overall distance: normalized MSE = inf
loss: 9.410881206393242; best overall distance: normalized MSE = inf
loss: 9.410498768091202; best overall distance: normalized MSE = inf
loss: 9.410096168518066; best overall distance: normalized MSE = inf
loss: 9.409726053476334; best overall distance: normalized MSE = inf
loss: 9.409337624907494; best overall distance: normalized MSE = inf
loss: 9.408932238817215; best overall distance: normalized MSE = inf
loss: 9.408564418554306; best overall distance: normalized MSE = inf
loss: 9.408194780349731; best overall distance: normalized MSE = inf
loss: 9.407793715596199; best overall distance: normalized MSE = inf
loss: 9.407413750886917; best overall distance: normalized MSE = inf
loss: 9.407018795609474; best overall distance: normalized MSE = inf
loss: 9.406596168875694; best overall distance: normalized MSE = inf
loss: 9.406171679496765; best overall distance: normalized MSE = inf
loss: 9.40572489798069; best overall distance: normalized MSE = inf
loss: 9.405301928520203; best overall distance: normalized MSE = inf
loss: 9.40489587187767; best overall distance: normalized MSE = inf
loss: 9.404474139213562; best overall distance: normalized MSE = inf
loss: 9.404070526361465; best overall distance: normalized MSE = inf
loss: 9.403714314103127; best overall distance: normalized MSE = inf
loss: 9.403378963470459; best overall distance: normalized MSE = inf
loss: 9.40304285287857; best overall distance: normalized MSE = inf
loss: 9.402681797742844; best overall distance: normalized MSE = inf
loss: 9.402312994003296; best overall distance: normalized MSE = inf
loss: 9.401961952447891; best overall distance: normalized MSE = inf
loss: 9.401622012257576; best overall distance: normalized MSE = inf
loss: 9.401312097907066; best overall distance: normalized MSE = inf
loss: 9.400994539260864; best overall distance: normalized MSE = inf
loss: 9.40071476995945; best overall distance: normalized MSE = inf
loss: 9.400439262390137; best overall distance: normalized MSE = inf
loss: 9.400172129273415; best overall distance: normalized MSE = inf
loss: 9.399914801120758; best overall distance: normalized MSE = inf
loss: 9.39969065785408; best overall distance: normalized MSE = inf
loss: 9.399428308010101; best overall distance: normalized MSE = inf
loss: 9.399181336164474; best overall distance: normalized MSE = inf
loss: 9.398947283625603; best overall distance: normalized MSE = inf
loss: 9.398719817399979; best overall distance: normalized MSE = inf
loss: 9.398521482944489; best overall distance: normalized MSE = inf
loss: 9.398355662822723; best overall distance: normalized MSE = inf
loss: 9.398161798715591; best overall distance: normalized MSE = inf
loss: 9.397954106330872; best overall distance: normalized MSE = inf
loss: 9.397782444953918; best overall distance: normalized MSE = inf
loss: 9.39759586751461; best overall distance: normalized MSE = inf
loss: 9.397390380501747; best overall distance: normalized MSE = inf
loss: 9.397198423743248; best overall distance: normalized MSE = inf
loss: 9.39700961112976; best overall distance: normalized MSE = inf
loss: 9.396844506263733; best overall distance: normalized MSE = inf
loss: 9.396655648946762; best overall distance: normalized MSE = inf
loss: 9.396458923816681; best overall distance: normalized MSE = inf
loss: 9.39631175994873; best overall distance: normalized MSE = inf
loss: 9.396176189184189; best overall distance: normalized MSE = inf
loss: 9.396052539348602; best overall distance: normalized MSE = inf
loss: 9.395882248878479; best overall distance: normalized MSE = inf
loss: 9.395698219537735; best overall distance: normalized MSE = inf
loss: 9.395544171333313; best overall distance: normalized MSE = inf
loss: 9.39545139670372; best overall distance: normalized MSE = inf
loss: 9.39535129070282; best overall distance: normalized MSE = inf
loss: 9.395238995552063; best overall distance: normalized MSE = inf
loss: 9.395099520683289; best overall distance: normalized MSE = inf
loss: 9.39495587348938; best overall distance: normalized MSE = inf
loss: 9.394867897033691; best overall distance: normalized MSE = inf
loss: 9.394773751497269; best overall distance: normalized MSE = inf
loss: 9.394663512706757; best overall distance: normalized MSE = inf
loss: 9.394570648670197; best overall distance: normalized MSE = inf
loss: 9.394469976425171; best overall distance: normalized MSE = inf
loss: 9.39442628622055; best overall distance: normalized MSE = inf
loss: 9.39435389637947; best overall distance: normalized MSE = inf
loss: 9.394252240657806; best overall distance: normalized MSE = inf
loss: 9.394179701805115; best overall distance: normalized MSE = inf
loss: 9.394073247909546; best overall distance: normalized MSE = inf
loss: 9.393986701965332; best overall distance: normalized MSE = inf
loss: 9.393902570009232; best overall distance: normalized MSE = inf
loss: 9.393843054771423; best overall distance: normalized MSE = inf
loss: 9.393777072429657; best overall distance: normalized MSE = inf
loss: 9.393687665462494; best overall distance: normalized MSE = inf
loss: 9.393610000610352; best overall distance: normalized MSE = inf
loss: 9.393537431955338; best overall distance: normalized MSE = inf
loss: 9.393446922302246; best overall distance: normalized MSE = inf
loss: 9.393399208784103; best overall distance: normalized MSE = inf
loss: 9.393356263637543; best overall distance: normalized MSE = inf
loss: 9.393281549215317; best overall distance: normalized MSE = inf
loss: 9.393218338489532; best overall distance: normalized MSE = inf
loss: 9.393169522285461; best overall distance: normalized MSE = inf
loss: 9.393098831176758; best overall distance: normalized MSE = inf
loss: 9.393000423908234; best overall distance: normalized MSE = inf
loss: 9.392932891845703; best overall distance: normalized MSE = inf
loss: 9.392889440059662; best overall distance: normalized MSE = inf
loss: 9.392816036939621; best overall distance: normalized MSE = inf
loss: 9.392723023891449; best overall distance: normalized MSE = inf
loss: 9.392669081687927; best overall distance: normalized MSE = inf
loss: 9.392606735229492; best overall distance: normalized MSE = inf
loss: 9.392530977725983; best overall distance: normalized MSE = inf
loss: 9.392445862293243; best overall distance: normalized MSE = inf
loss: 9.392366170883179; best overall distance: normalized MSE = inf
loss: 9.392305135726929; best overall distance: normalized MSE = inf
loss: 9.392240047454834; best overall distance: normalized MSE = inf
loss: 9.392178058624268; best overall distance: normalized MSE = inf
loss: 9.392103910446167; best overall distance: normalized MSE = inf
loss: 9.392042636871338; best overall distance: normalized MSE = inf
loss: 9.391985476016998; best overall distance: normalized MSE = inf
loss: 9.391919136047363; best overall distance: normalized MSE = inf
loss: 9.391894042491913; best overall distance: normalized MSE = inf
loss: 9.391823917627335; best overall distance: normalized MSE = inf
loss: 9.391751438379288; best overall distance: normalized MSE = inf
loss: 9.391705811023712; best overall distance: normalized MSE = inf
loss: 9.39165860414505; best overall distance: normalized MSE = inf
loss: 9.391593039035797; best overall distance: normalized MSE = inf
loss: 9.391522109508514; best overall distance: normalized MSE = inf
loss: 9.391452103853226; best overall distance: normalized MSE = inf
loss: 9.39138662815094; best overall distance: normalized MSE = inf
loss: 9.391334295272827; best overall distance: normalized MSE = inf
loss: 9.39127641916275; best overall distance: normalized MSE = inf
loss: 9.39120027422905; best overall distance: normalized MSE = inf
loss: 9.391100764274597; best overall distance: normalized MSE = inf
loss: 9.390996873378754; best overall distance: normalized MSE = inf
loss: 9.390908122062683; best overall distance: normalized MSE = inf
loss: 9.390805959701538; best overall distance: normalized MSE = inf
loss: 9.390690177679062; best overall distance: normalized MSE = inf
loss: 9.390552580356598; best overall distance: normalized MSE = inf
loss: 9.390426248311996; best overall distance: normalized MSE = inf
loss: 9.390305548906326; best overall distance: normalized MSE = inf
loss: 9.390194535255432; best overall distance: normalized MSE = inf
loss: 9.390117228031158; best overall distance: normalized MSE = inf
loss: 9.38998693227768; best overall distance: normalized MSE = inf
loss: 9.389913231134415; best overall distance: normalized MSE = inf
loss: 9.389860987663269; best overall distance: normalized MSE = inf
loss: 9.389790445566177; best overall distance: normalized MSE = inf
loss: 9.389694929122925; best overall distance: normalized MSE = inf
loss: 9.389621257781982; best overall distance: normalized MSE = inf
loss: 9.389556527137756; best overall distance: normalized MSE = inf
loss: 9.389490634202957; best overall distance: normalized MSE = inf
loss: 9.389377534389496; best overall distance: normalized MSE = inf
loss: 9.389296233654022; best overall distance: normalized MSE = inf
loss: 9.389200031757355; best overall distance: normalized MSE = inf
loss: 9.389100283384323; best overall distance: normalized MSE = inf
loss: 9.389012664556503; best overall distance: normalized MSE = inf
loss: 9.388935267925262; best overall distance: normalized MSE = inf
loss: 9.388828128576279; best overall distance: normalized MSE = inf
loss: 9.388748168945312; best overall distance: normalized MSE = inf
loss: 9.388692677021027; best overall distance: normalized MSE = inf
loss: 9.388627111911774; best overall distance: normalized MSE = inf
loss: 9.388567090034485; best overall distance: normalized MSE = inf
loss: 9.388497829437256; best overall distance: normalized MSE = inf
loss: 9.388439536094666; best overall distance: normalized MSE = inf
loss: 9.388392806053162; best overall distance: normalized MSE = inf
loss: 9.388326704502106; best overall distance: normalized MSE = inf
loss: 9.388269394636154; best overall distance: normalized MSE = inf
loss: 9.388235598802567; best overall distance: normalized MSE = inf
loss: 9.388196110725403; best overall distance: normalized MSE = inf
loss: 9.388141065835953; best overall distance: normalized MSE = inf
loss: 9.388084083795547; best overall distance: normalized MSE = inf
loss: 9.388049185276031; best overall distance: normalized MSE = inf
loss: 9.388013273477554; best overall distance: normalized MSE = inf
loss: 9.387962311506271; best overall distance: normalized MSE = inf
loss: 9.387904971837997; best overall distance: normalized MSE = inf
loss: 9.387866377830505; best overall distance: normalized MSE = inf
loss: 9.38782262802124; best overall distance: normalized MSE = inf
loss: 9.387781977653503; best overall distance: normalized MSE = inf
loss: 9.387729406356812; best overall distance: normalized MSE = inf
loss: 9.387672066688538; best overall distance: normalized MSE = inf
loss: 9.38763678073883; best overall distance: normalized MSE = inf
loss: 9.387602716684341; best overall distance: normalized MSE = inf
loss: 9.387561947107315; best overall distance: normalized MSE = inf
loss: 9.387500375509262; best overall distance: normalized MSE = inf
loss: 9.387451410293579; best overall distance: normalized MSE = inf
loss: 9.387412160634995; best overall distance: normalized MSE = inf
loss: 9.387381255626678; best overall distance: normalized MSE = inf
loss: 9.387300789356232; best overall distance: normalized MSE = inf
loss: 9.387278735637665; best overall distance: normalized MSE = inf
loss: 9.387247622013092; best overall distance: normalized MSE = inf
loss: 9.387220203876495; best overall distance: normalized MSE = inf
loss: 9.387160331010818; best overall distance: normalized MSE = inf
loss: 9.387095332145691; best overall distance: normalized MSE = inf
loss: 9.387037754058838; best overall distance: normalized MSE = inf
loss: 9.386986494064331; best overall distance: normalized MSE = inf
loss: 9.386932760477066; best overall distance: normalized MSE = inf
loss: 9.386885225772858; best overall distance: normalized MSE = inf
loss: 9.38682210445404; best overall distance: normalized MSE = inf
loss: 9.386768192052841; best overall distance: normalized MSE = inf
loss: 9.386717855930328; best overall distance: normalized MSE = inf
loss: 9.386648267507553; best overall distance: normalized MSE = inf
loss: 9.386577844619751; best overall distance: normalized MSE = inf
loss: 9.386520832777023; best overall distance: normalized MSE = inf
loss: 9.386433571577072; best overall distance: normalized MSE = inf
loss: 9.386386454105377; best overall distance: normalized MSE = inf
loss: 9.386322975158691; best overall distance: normalized MSE = inf
loss: 9.386257946491241; best overall distance: normalized MSE = inf
loss: 9.386194795370102; best overall distance: normalized MSE = inf
loss: 9.386099308729172; best overall distance: normalized MSE = inf
loss: 9.38600617647171; best overall distance: normalized MSE = inf
loss: 9.385935574769974; best overall distance: normalized MSE = inf
loss: 9.385903626680374; best overall distance: normalized MSE = inf
loss: 9.385816603899002; best overall distance: normalized MSE = inf
loss: 9.385738790035248; best overall distance: normalized MSE = inf
loss: 9.38566443324089; best overall distance: normalized MSE = inf
loss: 9.385588735342026; best overall distance: normalized MSE = inf
loss: 9.38550615310669; best overall distance: normalized MSE = inf
loss: 9.385434657335281; best overall distance: normalized MSE = inf
loss: 9.385370910167694; best overall distance: normalized MSE = inf
loss: 9.3852978348732; best overall distance: normalized MSE = inf
loss: 9.38520085811615; best overall distance: normalized MSE = inf
loss: 9.38513046503067; best overall distance: normalized MSE = inf
loss: 9.385055303573608; best overall distance: normalized MSE = inf
loss: 9.384966969490051; best overall distance: normalized MSE = inf
loss: 9.384875565767288; best overall distance: normalized MSE = inf
loss: 9.384795188903809; best overall distance: normalized MSE = inf
loss: 9.38470447063446; best overall distance: normalized MSE = inf
loss: 9.384609043598175; best overall distance: normalized MSE = inf
loss: 9.384554028511047; best overall distance: normalized MSE = inf
loss: 9.384444802999496; best overall distance: normalized MSE = inf
loss: 9.384360492229462; best overall distance: normalized MSE = inf
loss: 9.384257972240448; best overall distance: normalized MSE = inf
loss: 9.38416039943695; best overall distance: normalized MSE = inf
loss: 9.38406127691269; best overall distance: normalized MSE = inf
loss: 9.383934259414673; best overall distance: normalized MSE = inf
loss: 9.383844465017319; best overall distance: normalized MSE = inf
loss: 9.383746922016144; best overall distance: normalized MSE = inf
loss: 9.38361918926239; best overall distance: normalized MSE = inf
loss: 9.383496195077896; best overall distance: normalized MSE = inf
loss: 9.383366137742996; best overall distance: normalized MSE = inf
loss: 9.383253782987595; best overall distance: normalized MSE = inf
loss: 9.383115768432617; best overall distance: normalized MSE = inf
loss: 9.382972449064255; best overall distance: normalized MSE = inf
loss: 9.38282823562622; best overall distance: normalized MSE = inf
loss: 9.382698893547058; best overall distance: normalized MSE = inf
loss: 9.382552444934845; best overall distance: normalized MSE = inf
loss: 9.38239124417305; best overall distance: normalized MSE = inf
loss: 9.382238775491714; best overall distance: normalized MSE = inf
loss: 9.382073670625687; best overall distance: normalized MSE = inf
loss: 9.381897926330566; best overall distance: normalized MSE = inf
loss: 9.3817298412323; best overall distance: normalized MSE = inf
loss: 9.381542891263962; best overall distance: normalized MSE = inf
loss: 9.38136625289917; best overall distance: normalized MSE = inf
loss: 9.38117516040802; best overall distance: normalized MSE = inf
loss: 9.380981624126434; best overall distance: normalized MSE = inf
loss: 9.380776971578598; best overall distance: normalized MSE = inf
loss: 9.380563020706177; best overall distance: normalized MSE = inf
loss: 9.38034263253212; best overall distance: normalized MSE = inf
loss: 9.380112081766129; best overall distance: normalized MSE = inf
loss: 9.379892021417618; best overall distance: normalized MSE = inf
loss: 9.379657417535782; best overall distance: normalized MSE = inf
loss: 9.379395127296448; best overall distance: normalized MSE = inf
loss: 9.379125773906708; best overall distance: normalized MSE = inf
loss: 9.378853917121887; best overall distance: normalized MSE = inf
loss: 9.378590703010559; best overall distance: normalized MSE = inf
loss: 9.378301858901978; best overall distance: normalized MSE = inf
loss: 9.3780015707016; best overall distance: normalized MSE = inf
loss: 9.377687275409698; best overall distance: normalized MSE = inf
loss: 9.37736463546753; best overall distance: normalized MSE = inf
loss: 9.377024173736572; best overall distance: normalized MSE = inf
loss: 9.376697331666946; best overall distance: normalized MSE = inf
loss: 9.376339614391327; best overall distance: normalized MSE = inf
loss: 9.375968784093857; best overall distance: normalized MSE = inf
loss: 9.37559163570404; best overall distance: normalized MSE = inf
loss: 9.3751962184906; best overall distance: normalized MSE = inf
loss: 9.374784708023071; best overall distance: normalized MSE = inf
loss: 9.374367952346802; best overall distance: normalized MSE = inf
loss: 9.373908370733261; best overall distance: normalized MSE = inf
loss: 9.373460590839386; best overall distance: normalized MSE = inf
loss: 9.372999548912048; best overall distance: normalized MSE = inf
loss: 9.372499704360962; best overall distance: normalized MSE = inf
loss: 9.37198680639267; best overall distance: normalized MSE = inf
loss: 9.37144809961319; best overall distance: normalized MSE = inf
loss: 9.370912820100784; best overall distance: normalized MSE = inf
loss: 9.370337456464767; best overall distance: normalized MSE = inf
loss: 9.369746565818787; best overall distance: normalized MSE = inf
loss: 9.369133114814758; best overall distance: normalized MSE = inf
loss: 9.368502736091614; best overall distance: normalized MSE = inf
loss: 9.36784240603447; best overall distance: normalized MSE = inf
loss: 9.367176830768585; best overall distance: normalized MSE = inf
loss: 9.366495609283447; best overall distance: normalized MSE = inf
loss: 9.365754008293152; best overall distance: normalized MSE = inf
loss: 9.36499536037445; best overall distance: normalized MSE = inf
loss: 9.364231616258621; best overall distance: normalized MSE = inf
loss: 9.363416939973831; best overall distance: normalized MSE = inf
loss: 9.362606942653656; best overall distance: normalized MSE = inf
loss: 9.361757606267929; best overall distance: normalized MSE = inf
loss: 9.360887169837952; best overall distance: normalized MSE = inf
loss: 9.359948635101318; best overall distance: normalized MSE = inf
loss: 9.358978271484375; best overall distance: normalized MSE = inf
loss: 9.358045935630798; best overall distance: normalized MSE = inf
loss: 9.357033967971802; best overall distance: normalized MSE = inf
loss: 9.355980098247528; best overall distance: normalized MSE = inf
loss: 9.354858040809631; best overall distance: normalized MSE = inf
loss: 9.353724151849747; best overall distance: normalized MSE = inf
loss: 9.352548629045486; best overall distance: normalized MSE = inf
loss: 9.351352542638779; best overall distance: normalized MSE = inf
loss: 9.350109666585922; best overall distance: normalized MSE = inf
loss: 9.34884113073349; best overall distance: normalized MSE = inf
loss: 9.347512900829315; best overall distance: normalized MSE = inf
loss: 9.346182763576508; best overall distance: normalized MSE = inf
loss: 9.34471070766449; best overall distance: normalized MSE = inf
loss: 9.343218207359314; best overall distance: normalized MSE = inf
loss: 9.341691642999649; best overall distance: normalized MSE = inf
loss: 9.340126603841782; best overall distance: normalized MSE = inf
loss: 9.338503181934357; best overall distance: normalized MSE = inf
loss: 9.336784303188324; best overall distance: normalized MSE = inf
loss: 9.335063368082047; best overall distance: normalized MSE = inf
loss: 9.333379983901978; best overall distance: normalized MSE = inf
loss: 9.331528693437576; best overall distance: normalized MSE = inf
loss: 9.32969680428505; best overall distance: normalized MSE = inf
loss: 9.327794969081879; best overall distance: normalized MSE = inf
loss: 9.325891494750977; best overall distance: normalized MSE = inf
loss: 9.323905408382416; best overall distance: normalized MSE = inf
loss: 9.321777015924454; best overall distance: normalized MSE = inf
loss: 9.319662004709244; best overall distance: normalized MSE = inf
loss: 9.31748080253601; best overall distance: normalized MSE = inf
loss: 9.315227687358856; best overall distance: normalized MSE = inf
loss: 9.312819093465805; best overall distance: normalized MSE = inf
loss: 9.310499548912048; best overall distance: normalized MSE = inf
loss: 9.308080077171326; best overall distance: normalized MSE = inf
loss: 9.305615156888962; best overall distance: normalized MSE = inf
loss: 9.303114593029022; best overall distance: normalized MSE = inf
loss: 9.300481587648392; best overall distance: normalized MSE = inf
loss: 9.297894537448883; best overall distance: normalized MSE = inf
loss: 9.295240074396133; best overall distance: normalized MSE = inf
loss: 9.29254287481308; best overall distance: normalized MSE = inf
loss: 9.2897529900074; best overall distance: normalized MSE = inf
loss: 9.286862015724182; best overall distance: normalized MSE = inf
loss: 9.28388774394989; best overall distance: normalized MSE = inf
loss: 9.280839383602142; best overall distance: normalized MSE = inf
loss: 9.277766764163971; best overall distance: normalized MSE = inf
loss: 9.274404078722; best overall distance: normalized MSE = inf
loss: 9.27086478471756; best overall distance: normalized MSE = inf
loss: 9.26728481054306; best overall distance: normalized MSE = inf
loss: 9.263793140649796; best overall distance: normalized MSE = inf
loss: 9.260183155536652; best overall distance: normalized MSE = inf
loss: 9.256653547286987; best overall distance: normalized MSE = inf
loss: 9.252792000770569; best overall distance: normalized MSE = inf
loss: 9.24912241101265; best overall distance: normalized MSE = inf
loss: 9.245654433965683; best overall distance: normalized MSE = inf
loss: 9.242170751094818; best overall distance: normalized MSE = inf
loss: 9.238539010286331; best overall distance: normalized MSE = inf
loss: 9.234974801540375; best overall distance: normalized MSE = inf
loss: 9.231637716293335; best overall distance: normalized MSE = inf
loss: 9.228607088327408; best overall distance: normalized MSE = inf
loss: 9.225219279527664; best overall distance: normalized MSE = inf
loss: 9.222225695848465; best overall distance: normalized MSE = inf
loss: 9.21879518032074; best overall distance: normalized MSE = inf
loss: 9.215406566858292; best overall distance: normalized MSE = inf
loss: 9.212214678525925; best overall distance: normalized MSE = inf
loss: 9.208950906991959; best overall distance: normalized MSE = inf
loss: 9.205612301826477; best overall distance: normalized MSE = inf
loss: 9.202508926391602; best overall distance: normalized MSE = inf
loss: 9.199713468551636; best overall distance: normalized MSE = inf
loss: 9.196729362010956; best overall distance: normalized MSE = inf
loss: 9.194156527519226; best overall distance: normalized MSE = inf
loss: 9.19143494963646; best overall distance: normalized MSE = inf
loss: 9.189012587070465; best overall distance: normalized MSE = inf
loss: 9.186365842819214; best overall distance: normalized MSE = inf
loss: 9.183573722839355; best overall distance: normalized MSE = inf
loss: 9.181455254554749; best overall distance: normalized MSE = inf
loss: 9.178685426712036; best overall distance: normalized MSE = inf
loss: 9.176520466804504; best overall distance: normalized MSE = inf
loss: 9.174402296543121; best overall distance: normalized MSE = inf
loss: 9.172341227531433; best overall distance: normalized MSE = inf
loss: 9.17031317949295; best overall distance: normalized MSE = inf
loss: 9.168289422988892; best overall distance: normalized MSE = inf
loss: 9.16631531715393; best overall distance: normalized MSE = inf
loss: 9.164428055286407; best overall distance: normalized MSE = inf
loss: 9.162559866905212; best overall distance: normalized MSE = inf
loss: 9.160736799240112; best overall distance: normalized MSE = inf
loss: 9.158675849437714; best overall distance: normalized MSE = inf
loss: 9.156676650047302; best overall distance: normalized MSE = inf
loss: 9.154667437076569; best overall distance: normalized MSE = inf
loss: 9.152549028396606; best overall distance: normalized MSE = inf
loss: 9.150549173355103; best overall distance: normalized MSE = inf
loss: 9.148654520511627; best overall distance: normalized MSE = inf
loss: 9.146699905395508; best overall distance: normalized MSE = inf
loss: 9.144677758216858; best overall distance: normalized MSE = inf
loss: 9.142747521400452; best overall distance: normalized MSE = inf
loss: 9.140973389148712; best overall distance: normalized MSE = inf
loss: 9.139253616333008; best overall distance: normalized MSE = inf
loss: 9.13759970664978; best overall distance: normalized MSE = inf
loss: 9.135942578315735; best overall distance: normalized MSE = inf
loss: 9.134230256080627; best overall distance: normalized MSE = inf
loss: 9.132444739341736; best overall distance: normalized MSE = inf
loss: 9.130651950836182; best overall distance: normalized MSE = inf
loss: 9.128858923912048; best overall distance: normalized MSE = inf
loss: 9.127025485038757; best overall distance: normalized MSE = inf
loss: 9.125028729438782; best overall distance: normalized MSE = inf
loss: 9.123177647590637; best overall distance: normalized MSE = inf
loss: 9.1214359998703; best overall distance: normalized MSE = inf
loss: 9.119776606559753; best overall distance: normalized MSE = inf
loss: 9.118025302886963; best overall distance: normalized MSE = inf
loss: 9.116436004638672; best overall distance: normalized MSE = inf
loss: 9.114673912525177; best overall distance: normalized MSE = inf
loss: 9.112806975841522; best overall distance: normalized MSE = inf
loss: 9.110830903053284; best overall distance: normalized MSE = inf
loss: 9.1087327003479; best overall distance: normalized MSE = inf
loss: 9.10584819316864; best overall distance: normalized MSE = inf
loss: 9.102121710777283; best overall distance: normalized MSE = inf
loss: 9.098221004009247; best overall distance: normalized MSE = inf
loss: 9.094314217567444; best overall distance: normalized MSE = inf
loss: 9.089783787727356; best overall distance: normalized MSE = inf
loss: 9.085212111473083; best overall distance: normalized MSE = inf
loss: 9.08137971162796; best overall distance: normalized MSE = inf
loss: 9.07718700170517; best overall distance: normalized MSE = inf
loss: 9.072431206703186; best overall distance: normalized MSE = inf
loss: 9.06800490617752; best overall distance: normalized MSE = inf
loss: 9.063682973384857; best overall distance: normalized MSE = inf
loss: 9.059156894683838; best overall distance: normalized MSE = inf
loss: 9.054633796215057; best overall distance: normalized MSE = inf
loss: 9.049933552742004; best overall distance: normalized MSE = inf
loss: 9.045616149902344; best overall distance: normalized MSE = inf
loss: 9.042150318622589; best overall distance: normalized MSE = inf
loss: 9.039426326751709; best overall distance: normalized MSE = inf
loss: 9.036232948303223; best overall distance: normalized MSE = inf
loss: 9.033244371414185; best overall distance: normalized MSE = inf
loss: 9.03023362159729; best overall distance: normalized MSE = inf
loss: 9.027236461639404; best overall distance: normalized MSE = inf
loss: 9.023847579956055; best overall distance: normalized MSE = inf
loss: 9.021116495132446; best overall distance: normalized MSE = inf
loss: 9.01839804649353; best overall distance: normalized MSE = inf
loss: 9.015645027160645; best overall distance: normalized MSE = inf
loss: 9.012738943099976; best overall distance: normalized MSE = inf
loss: 9.009897112846375; best overall distance: normalized MSE = inf
loss: 9.00580644607544; best overall distance: normalized MSE = inf
loss: 9.00145673751831; best overall distance: normalized MSE = inf
loss: 8.997442364692688; best overall distance: normalized MSE = inf
loss: 8.993245363235474; best overall distance: normalized MSE = inf
loss: 8.979597806930542; best overall distance: normalized MSE = inf
loss: 8.940611720085144; best overall distance: normalized MSE = inf
loss: 8.888458251953125; best overall distance: normalized MSE = inf
loss: 8.826371788978577; best overall distance: normalized MSE = inf
loss: 8.757148027420044; best overall distance: normalized MSE = inf
loss: 8.682235717773438; best overall distance: normalized MSE = inf
loss: 8.600725412368774; best overall distance: normalized MSE = inf
loss: 8.517277717590332; best overall distance: normalized MSE = inf
loss: 8.431627988815308; best overall distance: normalized MSE = inf
loss: 8.345482110977173; best overall distance: normalized MSE = inf
loss: 8.24793028831482; best overall distance: normalized MSE = inf
loss: 8.080272436141968; best overall distance: normalized MSE = inf
loss: 7.882758140563965; best overall distance: normalized MSE = inf
loss: 7.670728921890259; best overall distance: normalized MSE = inf
loss: 7.4420952796936035; best overall distance: normalized MSE = inf
loss: 7.206571578979492; best overall distance: normalized MSE = inf
loss: 6.961183547973633; best overall distance: normalized MSE = inf
loss: 6.6972336769104; best overall distance: normalized MSE = inf
loss: 6.423412799835205; best overall distance: normalized MSE = inf
loss: 6.146047115325928; best overall distance: normalized MSE = inf
loss: 5.874547004699707; best overall distance: normalized MSE = inf
loss: 5.602904319763184; best overall distance: normalized MSE = inf
loss: 5.330522060394287; best overall distance: normalized MSE = inf
loss: 5.064030408859253; best overall distance: normalized MSE = inf
loss: 4.795783042907715; best overall distance: normalized MSE = inf
loss: 4.533802509307861; best overall distance: normalized MSE = inf
loss: 4.381749629974365; best overall distance: normalized MSE = 5.59e-03
loss: 4.509882926940918; best overall distance: normalized MSE = 5.59e-03
loss: 4.580306529998779; best overall distance: normalized MSE = 5.59e-03
loss: 4.603743553161621; best overall distance: normalized MSE = 5.59e-03
loss: 4.588878154754639; best overall distance: normalized MSE = 5.59e-03
loss: 4.543058395385742; best overall distance: normalized MSE = 5.59e-03
loss: 4.472565650939941; best overall distance: normalized MSE = 5.59e-03
loss: 4.382762908935547; best overall distance: normalized MSE = 5.59e-03
loss: 4.2782087326049805; best overall distance: normalized MSE = 5.46e-03
loss: 4.162754058837891; best overall distance: normalized MSE = 5.31e-03
loss: 4.039624214172363; best overall distance: normalized MSE = 5.15e-03
loss: 3.911501884460449; best overall distance: normalized MSE = 4.99e-03
loss: 3.876185655593872; best overall distance: normalized MSE = 4.99e-03
loss: 3.923544406890869; best overall distance: normalized MSE = 4.99e-03
loss: 3.930011749267578; best overall distance: normalized MSE = 4.99e-03
loss: 3.901362895965576; best overall distance: normalized MSE = 4.99e-03
loss: 3.8429007530212402; best overall distance: normalized MSE = 4.99e-03
loss: 3.758657455444336; best overall distance: normalized MSE = 4.99e-03
loss: 3.653703212738037; best overall distance: normalized MSE = 4.99e-03
loss: 3.662494421005249; best overall distance: normalized MSE = 4.67e-03
loss: 3.686018228530884; best overall distance: normalized MSE = 4.67e-03
loss: 3.690868854522705; best overall distance: normalized MSE = 4.67e-03
loss: 3.67905855178833; best overall distance: normalized MSE = 4.67e-03
loss: 3.6526074409484863; best overall distance: normalized MSE = 4.66e-03
loss: 3.6134932041168213; best overall distance: normalized MSE = 4.61e-03
loss: 3.563610792160034; best overall distance: normalized MSE = 4.55e-03
loss: 3.5047428607940674; best overall distance: normalized MSE = 4.47e-03
loss: 3.4441399574279785; best overall distance: normalized MSE = 4.47e-03
loss: 3.4614977836608887; best overall distance: normalized MSE = 4.47e-03
loss: 3.447009801864624; best overall distance: normalized MSE = 4.47e-03
loss: 3.4054083824157715; best overall distance: normalized MSE = 4.47e-03
loss: 3.3956470489501953; best overall distance: normalized MSE = 4.33e-03
loss: 3.398043155670166; best overall distance: normalized MSE = 4.33e-03
loss: 3.3873353004455566; best overall distance: normalized MSE = 4.32e-03
loss: 3.365063428878784; best overall distance: normalized MSE = 4.29e-03
loss: 3.3327274322509766; best overall distance: normalized MSE = 4.25e-03
loss: 3.3296103477478027; best overall distance: normalized MSE = 4.25e-03
loss: 3.325716018676758; best overall distance: normalized MSE = 4.25e-03
loss: 3.288203239440918; best overall distance: normalized MSE = 4.25e-03
loss: 3.2908732891082764; best overall distance: normalized MSE = 4.20e-03
loss: 3.295161247253418; best overall distance: normalized MSE = 4.20e-03
loss: 3.2874879837036133; best overall distance: normalized MSE = 4.19e-03
loss: 3.269183874130249; best overall distance: normalized MSE = 4.17e-03
loss: 3.241560220718384; best overall distance: normalized MSE = 4.13e-03
loss: 3.210634708404541; best overall distance: normalized MSE = 4.13e-03
loss: 3.204824924468994; best overall distance: normalized MSE = 4.13e-03
loss: 3.19467830657959; best overall distance: normalized MSE = 4.07e-03
loss: 3.1873350143432617; best overall distance: normalized MSE = 4.07e-03
loss: 3.1702980995178223; best overall distance: normalized MSE = 4.04e-03
loss: 3.1638035774230957; best overall distance: normalized MSE = 4.04e-03
loss: 3.145663261413574; best overall distance: normalized MSE = 4.04e-03
loss: 3.1497840881347656; best overall distance: normalized MSE = 4.02e-03
loss: 3.1498870849609375; best overall distance: normalized MSE = 4.02e-03
loss: 3.140047311782837; best overall distance: normalized MSE = 4.01e-03
loss: 3.1214022636413574; best overall distance: normalized MSE = 3.98e-03
loss: 3.0950546264648438; best overall distance: normalized MSE = 3.95e-03
loss: 3.1271190643310547; best overall distance: normalized MSE = 3.95e-03
loss: 3.1263084411621094; best overall distance: normalized MSE = 3.95e-03
loss: 3.0914525985717773; best overall distance: normalized MSE = 3.95e-03
loss: 3.0728390216827393; best overall distance: normalized MSE = 3.92e-03
loss: 3.081625461578369; best overall distance: normalized MSE = 3.92e-03
loss: 3.0804362297058105; best overall distance: normalized MSE = 3.92e-03
loss: 3.0703113079071045; best overall distance: normalized MSE = 3.92e-03
loss: 3.0522727966308594; best overall distance: normalized MSE = 3.89e-03
loss: 3.027310371398926; best overall distance: normalized MSE = 3.86e-03
loss: 3.045410394668579; best overall distance: normalized MSE = 3.86e-03
loss: 3.0492684841156006; best overall distance: normalized MSE = 3.86e-03
loss: 3.0221378803253174; best overall distance: normalized MSE = 3.86e-03
loss: 3.0057718753814697; best overall distance: normalized MSE = 3.83e-03
loss: 3.0136899948120117; best overall distance: normalized MSE = 3.83e-03
loss: 3.012449264526367; best overall distance: normalized MSE = 3.83e-03
loss: 3.0029940605163574; best overall distance: normalized MSE = 3.83e-03
loss: 2.986253499984741; best overall distance: normalized MSE = 3.81e-03
loss: 2.9631240367889404; best overall distance: normalized MSE = 3.78e-03
loss: 3.000823736190796; best overall distance: normalized MSE = 3.78e-03
loss: 3.0063881874084473; best overall distance: normalized MSE = 3.78e-03
loss: 2.981832981109619; best overall distance: normalized MSE = 3.78e-03
loss: 2.944763660430908; best overall distance: normalized MSE = 3.76e-03
loss: 2.9528958797454834; best overall distance: normalized MSE = 3.76e-03
loss: 2.952446222305298; best overall distance: normalized MSE = 3.76e-03
loss: 2.9442861080169678; best overall distance: normalized MSE = 3.76e-03
loss: 2.9292726516723633; best overall distance: normalized MSE = 3.74e-03
loss: 2.922213077545166; best overall distance: normalized MSE = 3.74e-03
loss: 2.9143640995025635; best overall distance: normalized MSE = 3.74e-03
loss: 2.914235830307007; best overall distance: normalized MSE = 3.72e-03
loss: 2.9161477088928223; best overall distance: normalized MSE = 3.72e-03
loss: 2.910475015640259; best overall distance: normalized MSE = 3.71e-03
loss: 2.8980398178100586; best overall distance: normalized MSE = 3.70e-03
loss: 2.8845839500427246; best overall distance: normalized MSE = 3.70e-03
loss: 2.8774967193603516; best overall distance: normalized MSE = 3.67e-03
loss: 2.8779144287109375; best overall distance: normalized MSE = 3.67e-03
loss: 2.8743677139282227; best overall distance: normalized MSE = 3.67e-03
loss: 2.8726556301116943; best overall distance: normalized MSE = 3.66e-03
loss: 2.8641223907470703; best overall distance: normalized MSE = 3.65e-03
loss: 2.8597166538238525; best overall distance: normalized MSE = 3.65e-03
loss: 2.8503777980804443; best overall distance: normalized MSE = 3.64e-03
loss: 2.8443245887756348; best overall distance: normalized MSE = 3.63e-03
loss: 2.8556747436523438; best overall distance: normalized MSE = 3.63e-03
loss: 2.8351733684539795; best overall distance: normalized MSE = 3.63e-03
loss: 2.851393461227417; best overall distance: normalized MSE = 3.63e-03
loss: 2.8594446182250977; best overall distance: normalized MSE = 3.63e-03
loss: 2.859996795654297; best overall distance: normalized MSE = 3.63e-03
loss: 2.8538074493408203; best overall distance: normalized MSE = 3.63e-03
loss: 2.8416128158569336; best overall distance: normalized MSE = 3.62e-03
loss: 2.8241209983825684; best overall distance: normalized MSE = 3.60e-03
loss: 2.8203697204589844; best overall distance: normalized MSE = 3.60e-03
loss: 2.8225228786468506; best overall distance: normalized MSE = 3.60e-03
loss: 2.803386926651001; best overall distance: normalized MSE = 3.58e-03
loss: 2.8040010929107666; best overall distance: normalized MSE = 3.58e-03
loss: 2.798267364501953; best overall distance: normalized MSE = 3.57e-03
loss: 2.794884443283081; best overall distance: normalized MSE = 3.57e-03
loss: 2.7893314361572266; best overall distance: normalized MSE = 3.56e-03
loss: 2.7853846549987793; best overall distance: normalized MSE = 3.55e-03
loss: 2.781604051589966; best overall distance: normalized MSE = 3.55e-03
loss: 2.7795522212982178; best overall distance: normalized MSE = 3.55e-03
loss: 2.776954412460327; best overall distance: normalized MSE = 3.54e-03
loss: 2.768582582473755; best overall distance: normalized MSE = 3.53e-03
loss: 2.778176784515381; best overall distance: normalized MSE = 3.53e-03
loss: 2.7659738063812256; best overall distance: normalized MSE = 3.53e-03
loss: 2.7668933868408203; best overall distance: normalized MSE = 3.53e-03
loss: 2.77168607711792; best overall distance: normalized MSE = 3.53e-03
loss: 2.7700839042663574; best overall distance: normalized MSE = 3.53e-03
loss: 2.762734889984131; best overall distance: normalized MSE = 3.52e-03
loss: 2.7502670288085938; best overall distance: normalized MSE = 3.51e-03
loss: 2.7447311878204346; best overall distance: normalized MSE = 3.51e-03
loss: 2.7423675060272217; best overall distance: normalized MSE = 3.51e-03
loss: 2.7375125885009766; best overall distance: normalized MSE = 3.49e-03
loss: 2.738990068435669; best overall distance: normalized MSE = 3.49e-03
loss: 2.7346012592315674; best overall distance: normalized MSE = 3.49e-03
loss: 2.724958896636963; best overall distance: normalized MSE = 3.48e-03
loss: 2.7343883514404297; best overall distance: normalized MSE = 3.48e-03
loss: 2.7277376651763916; best overall distance: normalized MSE = 3.48e-03
loss: 2.7199954986572266; best overall distance: normalized MSE = 3.47e-03
loss: 2.723909378051758; best overall distance: normalized MSE = 3.47e-03
loss: 2.721839189529419; best overall distance: normalized MSE = 3.47e-03
loss: 2.7143936157226562; best overall distance: normalized MSE = 3.46e-03
loss: 2.7021591663360596; best overall distance: normalized MSE = 3.45e-03
loss: 2.729947090148926; best overall distance: normalized MSE = 3.45e-03
loss: 2.7292709350585938; best overall distance: normalized MSE = 3.45e-03
loss: 2.703338146209717; best overall distance: normalized MSE = 3.45e-03
loss: 2.709088087081909; best overall distance: normalized MSE = 3.45e-03
loss: 2.720411777496338; best overall distance: normalized MSE = 3.45e-03
loss: 2.7251386642456055; best overall distance: normalized MSE = 3.45e-03
loss: 2.7238755226135254; best overall distance: normalized MSE = 3.45e-03
loss: 2.7172200679779053; best overall distance: normalized MSE = 3.45e-03
loss: 2.7057528495788574; best overall distance: normalized MSE = 3.45e-03
loss: 2.690028667449951; best overall distance: normalized MSE = 3.43e-03
loss: 2.687976837158203; best overall distance: normalized MSE = 3.43e-03
loss: 2.694969654083252; best overall distance: normalized MSE = 3.43e-03
loss: 2.6769042015075684; best overall distance: normalized MSE = 3.43e-03
loss: 2.6845269203186035; best overall distance: normalized MSE = 3.42e-03
loss: 2.6930620670318604; best overall distance: normalized MSE = 3.42e-03
loss: 2.6954288482666016; best overall distance: normalized MSE = 3.42e-03
loss: 2.692214250564575; best overall distance: normalized MSE = 3.42e-03
loss: 2.683992385864258; best overall distance: normalized MSE = 3.42e-03
loss: 2.6713171005249023; best overall distance: normalized MSE = 3.41e-03
loss: 2.6622202396392822; best overall distance: normalized MSE = 3.41e-03
loss: 2.664517641067505; best overall distance: normalized MSE = 3.41e-03
loss: 2.6578845977783203; best overall distance: normalized MSE = 3.39e-03
loss: 2.6592020988464355; best overall distance: normalized MSE = 3.39e-03
loss: 2.6552257537841797; best overall distance: normalized MSE = 3.39e-03
loss: 2.6479060649871826; best overall distance: normalized MSE = 3.39e-03
loss: 2.6492841243743896; best overall distance: normalized MSE = 3.38e-03
loss: 2.646682024002075; best overall distance: normalized MSE = 3.38e-03
loss: 2.644247531890869; best overall distance: normalized MSE = 3.38e-03
loss: 2.6429977416992188; best overall distance: normalized MSE = 3.37e-03
loss: 2.6413156986236572; best overall distance: normalized MSE = 3.37e-03
loss: 2.6347482204437256; best overall distance: normalized MSE = 3.36e-03
loss: 2.6519103050231934; best overall distance: normalized MSE = 3.36e-03
loss: 2.643648147583008; best overall distance: normalized MSE = 3.36e-03
loss: 2.6355936527252197; best overall distance: normalized MSE = 3.36e-03
loss: 2.6405537128448486; best overall distance: normalized MSE = 3.36e-03
loss: 2.6400089263916016; best overall distance: normalized MSE = 3.36e-03
loss: 2.634500741958618; best overall distance: normalized MSE = 3.36e-03
loss: 2.624554395675659; best overall distance: normalized MSE = 3.35e-03
loss: 2.6374855041503906; best overall distance: normalized MSE = 3.35e-03
loss: 2.6360929012298584; best overall distance: normalized MSE = 3.35e-03
loss: 2.617029905319214; best overall distance: normalized MSE = 3.34e-03
loss: 2.619741916656494; best overall distance: normalized MSE = 3.34e-03
loss: 2.6172707080841064; best overall distance: normalized MSE = 3.34e-03
loss: 2.6101417541503906; best overall distance: normalized MSE = 3.33e-03
loss: 2.6296536922454834; best overall distance: normalized MSE = 3.33e-03
loss: 2.6236495971679688; best overall distance: normalized MSE = 3.33e-03
loss: 2.609969139099121; best overall distance: normalized MSE = 3.33e-03
loss: 2.61488938331604; best overall distance: normalized MSE = 3.33e-03
loss: 2.6144583225250244; best overall distance: normalized MSE = 3.33e-03
loss: 2.6092071533203125; best overall distance: normalized MSE = 3.33e-03
loss: 2.599649429321289; best overall distance: normalized MSE = 3.32e-03
loss: 2.623070240020752; best overall distance: normalized MSE = 3.32e-03
loss: 2.6210873126983643; best overall distance: normalized MSE = 3.32e-03
loss: 2.594503879547119; best overall distance: normalized MSE = 3.32e-03
loss: 2.613097906112671; best overall distance: normalized MSE = 3.32e-03
loss: 2.625363826751709; best overall distance: normalized MSE = 3.32e-03
loss: 2.6316070556640625; best overall distance: normalized MSE = 3.32e-03
loss: 2.632373332977295; best overall distance: normalized MSE = 3.32e-03
loss: 2.6282002925872803; best overall distance: normalized MSE = 3.32e-03
loss: 2.6196084022521973; best overall distance: normalized MSE = 3.32e-03
loss: 2.607095956802368; best overall distance: normalized MSE = 3.32e-03
loss: 2.591134786605835; best overall distance: normalized MSE = 3.31e-03
loss: 2.6041266918182373; best overall distance: normalized MSE = 3.31e-03
loss: 2.615114688873291; best overall distance: normalized MSE = 3.31e-03
loss: 2.600475549697876; best overall distance: normalized MSE = 3.31e-03
loss: 2.5840628147125244; best overall distance: normalized MSE = 3.30e-03
loss: 2.5922622680664062; best overall distance: normalized MSE = 3.30e-03
loss: 2.5950112342834473; best overall distance: normalized MSE = 3.30e-03
loss: 2.5928282737731934; best overall distance: normalized MSE = 3.30e-03
loss: 2.5862152576446533; best overall distance: normalized MSE = 3.30e-03
loss: 2.5756568908691406; best overall distance: normalized MSE = 3.29e-03
loss: 2.5914430618286133; best overall distance: normalized MSE = 3.29e-03
loss: 2.592916488647461; best overall distance: normalized MSE = 3.29e-03
loss: 2.5701346397399902; best overall distance: normalized MSE = 3.29e-03
loss: 2.5850112438201904; best overall distance: normalized MSE = 3.29e-03
loss: 2.596280097961426; best overall distance: normalized MSE = 3.29e-03
loss: 2.6018474102020264; best overall distance: normalized MSE = 3.29e-03
loss: 2.6022331714630127; best overall distance: normalized MSE = 3.29e-03
loss: 2.5979461669921875; best overall distance: normalized MSE = 3.29e-03
loss: 2.589479446411133; best overall distance: normalized MSE = 3.29e-03
loss: 2.5773024559020996; best overall distance: normalized MSE = 3.29e-03
loss: 2.561859130859375; best overall distance: normalized MSE = 3.27e-03
loss: 2.5946035385131836; best overall distance: normalized MSE = 3.27e-03
loss: 2.6060168743133545; best overall distance: normalized MSE = 3.27e-03
loss: 2.5920286178588867; best overall distance: normalized MSE = 3.27e-03
loss: 2.5562915802001953; best overall distance: normalized MSE = 3.27e-03
loss: 2.5784339904785156; best overall distance: normalized MSE = 3.27e-03
loss: 2.5944390296936035; best overall distance: normalized MSE = 3.27e-03
loss: 2.6043848991394043; best overall distance: normalized MSE = 3.27e-03
loss: 2.6087920665740967; best overall distance: normalized MSE = 3.27e-03
loss: 2.60817551612854; best overall distance: normalized MSE = 3.27e-03
loss: 2.6030380725860596; best overall distance: normalized MSE = 3.27e-03
loss: 2.5938642024993896; best overall distance: normalized MSE = 3.27e-03
loss: 2.581113576889038; best overall distance: normalized MSE = 3.27e-03
loss: 2.565220355987549; best overall distance: normalized MSE = 3.27e-03
loss: 2.5488407611846924; best overall distance: normalized MSE = 3.27e-03
loss: 2.561540126800537; best overall distance: normalized MSE = 3.27e-03
loss: 2.5492923259735107; best overall distance: normalized MSE = 3.27e-03
loss: 2.5571887493133545; best overall distance: normalized MSE = 3.26e-03
loss: 2.564965009689331; best overall distance: normalized MSE = 3.26e-03
loss: 2.567603349685669; best overall distance: normalized MSE = 3.26e-03
loss: 2.5655927658081055; best overall distance: normalized MSE = 3.26e-03
loss: 2.5594053268432617; best overall distance: normalized MSE = 3.26e-03
loss: 2.5494956970214844; best overall distance: normalized MSE = 3.25e-03
loss: 2.547145128250122; best overall distance: normalized MSE = 3.25e-03
loss: 2.54923415184021; best overall distance: normalized MSE = 3.25e-03
loss: 2.542468786239624; best overall distance: normalized MSE = 3.24e-03
loss: 2.5455198287963867; best overall distance: normalized MSE = 3.24e-03
loss: 2.543982982635498; best overall distance: normalized MSE = 3.24e-03
loss: 2.538320541381836; best overall distance: normalized MSE = 3.24e-03
loss: 2.5501739978790283; best overall distance: normalized MSE = 3.24e-03
loss: 2.544597864151001; best overall distance: normalized MSE = 3.24e-03
loss: 2.5411620140075684; best overall distance: normalized MSE = 3.24e-03
loss: 2.5467183589935303; best overall distance: normalized MSE = 3.24e-03
loss: 2.547459363937378; best overall distance: normalized MSE = 3.24e-03
loss: 2.5438525676727295; best overall distance: normalized MSE = 3.24e-03
loss: 2.5363504886627197; best overall distance: normalized MSE = 3.24e-03
loss: 2.542231559753418; best overall distance: normalized MSE = 3.24e-03
loss: 2.5404603481292725; best overall distance: normalized MSE = 3.24e-03
loss: 2.5346293449401855; best overall distance: normalized MSE = 3.23e-03
loss: 2.538937568664551; best overall distance: normalized MSE = 3.23e-03
loss: 2.538595676422119; best overall distance: normalized MSE = 3.23e-03
loss: 2.5340654850006104; best overall distance: normalized MSE = 3.23e-03
loss: 2.528999090194702; best overall distance: normalized MSE = 3.23e-03
loss: 2.527900218963623; best overall distance: normalized MSE = 3.22e-03
loss: 2.525623321533203; best overall distance: normalized MSE = 3.22e-03
loss: 2.5382487773895264; best overall distance: normalized MSE = 3.22e-03
loss: 2.527214527130127; best overall distance: normalized MSE = 3.22e-03
loss: 2.5363473892211914; best overall distance: normalized MSE = 3.22e-03
loss: 2.5439352989196777; best overall distance: normalized MSE = 3.22e-03
loss: 2.5465736389160156; best overall distance: normalized MSE = 3.22e-03
loss: 2.544734001159668; best overall distance: normalized MSE = 3.22e-03
loss: 2.5388734340667725; best overall distance: normalized MSE = 3.22e-03
loss: 2.5294277667999268; best overall distance: normalized MSE = 3.22e-03
loss: 2.529816150665283; best overall distance: normalized MSE = 3.22e-03
loss: 2.5321919918060303; best overall distance: normalized MSE = 3.22e-03
loss: 2.5228800773620605; best overall distance: normalized MSE = 3.22e-03
loss: 2.5258493423461914; best overall distance: normalized MSE = 3.22e-03
loss: 2.524404287338257; best overall distance: normalized MSE = 3.22e-03
loss: 2.5189921855926514; best overall distance: normalized MSE = 3.21e-03
loss: 2.5352909564971924; best overall distance: normalized MSE = 3.21e-03
loss: 2.530486822128296; best overall distance: normalized MSE = 3.21e-03
loss: 2.521873950958252; best overall distance: normalized MSE = 3.21e-03
loss: 2.5272774696350098; best overall distance: normalized MSE = 3.21e-03
loss: 2.528045892715454; best overall distance: normalized MSE = 3.21e-03
loss: 2.524632692337036; best overall distance: normalized MSE = 3.21e-03
loss: 2.5174732208251953; best overall distance: normalized MSE = 3.21e-03
loss: 2.5309500694274902; best overall distance: normalized MSE = 3.21e-03
loss: 2.5294785499572754; best overall distance: normalized MSE = 3.21e-03
loss: 2.516125440597534; best overall distance: normalized MSE = 3.21e-03
loss: 2.5204055309295654; best overall distance: normalized MSE = 3.21e-03
/Users/limuyang/Nustore Files/First Half of Junior Year/John/torchdiffeq/fooling/ode_fooling.py
import argparse
import logging
import os

import foolbox
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

DOWNLOAD_MNIST = False
use_gray = False

parser = argparse.ArgumentParser()
parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')
parser.add_argument('--tol', type=float, default=1e-3)
parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])
parser.add_argument('--downsampling-method', type=str, default='res', choices=['conv', 'res'])
parser.add_argument('--nepochs', type=int, default=160)
parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])
parser.add_argument('--lr', type=float, default=0.1)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--continuing', type=eval, default=False, choices=[True, False])
parser.add_argument('--save', type=str, default='./experiment1')
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint


def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)


def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


def norm(dim):
    return nn.GroupNorm(min(32, dim), dim)


def my_show_transform(x, use_gray):
    x = (x + 1.0) / 2.0
    """Imshow for Tensor."""
    x = np.clip(x, 0, 1)
    if use_gray:
        plt.imshow(x, cmap='gray')
    else:
        plt.imshow(x)
    return x


class ResBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(ResBlock, self).__init__()
        self.norm1 = norm(inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.norm2 = norm(planes)
        self.conv2 = conv3x3(planes, planes)

    def forward(self, x):
        shortcut = x

        out = self.relu(self.norm1(x))

        if self.downsample is not None:
            shortcut = self.downsample(out)

        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)

        return out + shortcut


class ODEfunc(nn.Module):

    def __init__(self, dim):
        super(ODEfunc, self).__init__()
        self.norm1 = norm(dim)
        self.relu = nn.ReLU(inplace=True)
        self.conv1 = conv3x3(dim, dim)
        self.norm2 = norm(dim)
        self.conv2 = conv3x3(dim, dim)
        self.norm3 = norm(dim)
        self.nfe = 0

    def forward(self, t, x):
        self.nfe += 1
        out = self.norm1(x)
        out = self.relu(out)
        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.norm3(out)
        return out


class ODEBlock(nn.Module):

    def __init__(self, odefunc):
        super(ODEBlock, self).__init__()
        self.odefunc = odefunc
        self.integration_time = torch.tensor([0, 1]).float()

    def forward(self, x):
        self.integration_time = self.integration_time.type_as(x)
        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)
        return out[1]

    @property
    def nfe(self):
        return self.odefunc.nfe

    @nfe.setter
    def nfe(self, value):
        self.odefunc.nfe = value


class Flatten(nn.Module):

    def __init__(self):
        super(Flatten, self).__init__()

    def forward(self, x):
        shape = torch.prod(torch.tensor(x.shape[1:])).item()
        return x.view(-1, shape)


class RunningAverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self, momentum=0.99):
        self.momentum = momentum
        self.reset()

    def reset(self):
        self.val = None
        self.avg = 0

    def update(self, val):
        if self.val is None:
            self.avg = val
        else:
            self.avg = self.avg * self.momentum + val * (1 - self.momentum)
        self.val = val


def inf_generator(iterable):
    """Allows training with DataLoaders in a single infinite loop:
        for i, (x, y) in enumerate(inf_generator(train_loader)):
    """
    iterator = iterable.__iter__()
    while True:
        try:
            yield iterator.__next__()
        except StopIteration:
            iterator = iterable.__iter__()


def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):
    initial_learning_rate = args.lr * batch_size / batch_denom

    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]
    vals = [initial_learning_rate * decay for decay in decay_rates]

    def learning_rate_fn(itr):
        lt = [itr < b for b in boundaries] + [True]
        i = np.argmax(lt)
        return vals[i]

    return learning_rate_fn


def one_hot(x, K):
    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)


def accuracy(model, dataset_loader):
    total_correct = 0
    for x, y in dataset_loader:
        x = x.to(device)
        y = one_hot(np.array(y.numpy()), 10)

        target_class = np.argmax(y, axis=1)
        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)
        total_correct += np.sum(predicted_class == target_class)
    return total_correct / len(dataset_loader.dataset)


def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def makedirs(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):
    logger = logging.getLogger()
    if debug:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logger.setLevel(level)
    if saving:
        info_file_handler = logging.FileHandler(logpath, mode="a")
        info_file_handler.setLevel(level)
        logger.addHandler(info_file_handler)
    if displaying:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        logger.addHandler(console_handler)
    logger.info(filepath)
    with open(filepath, "r") as f:
        logger.info(f.read())

    for f in package_files:
        logger.info(f)
        with open(f, "r") as package_f:
            logger.info(package_f.read())

    return logger


if __name__ == '__main__':

    makedirs(args.save)
    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)

    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')

    is_odenet = args.network == 'odenet'

    if args.downsampling_method == 'conv':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
        ]
    elif args.downsampling_method == 'res':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
        ]

    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]
    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]

    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)

    # pay attention to this!! 
    SET_CONTINUE = True
    if args.continuing or SET_CONTINUE:
        model.load_state_dict(torch.load('model.pth', map_location='cpu')['state_dict'])

    mean = np.array([0.5])
    std = np.array([0.5])

    fmodel = foolbox.models.PyTorchModel(
        model, bounds=(-1, 1), num_classes=10, preprocessing=(mean, std))

    # get source image and label
    my_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])

    test_data = torchvision.datasets.MNIST(
        root='./mnist',
        train=False,
        download=DOWNLOAD_MNIST,
        transform=my_transform
    )

    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)

    for batch_idx, (data, target) in enumerate(test_loader):
        label = target.data.numpy()[0]
        print('label', label)
        image = data.squeeze(0).cpu().numpy()
        plt.subplot(1, 2, 1)
        my_show_transform(image.squeeze(), use_gray)
        predict = np.argmax(fmodel.predictions(image))
        print('predicted class', predict)

        method_name = 'DeepFoolL2Attack'
        save_path = os.path.join(r'log/result_pic', method_name)
        makedirs(save_path)

        attack = foolbox.attacks.DeepFoolL2Attack()  # (fmodel)

        criterion = foolbox.criteria.Misclassification()
        adversarial = foolbox.Adversarial(fmodel, criterion, image, np.array(label, dtype=np.int64),
                                          distance=foolbox.distances.MSE)
        attack(adversarial)
        adversarial = adversarial.image

        adversarial_predict = np.argmax(fmodel.predictions(adversarial))
        print('adversarial class', adversarial_predict)
        plt.subplot(1, 2, 2)

        if use_gray:
            plt.imshow(adversarial.squeeze(), cmap='gray')
        else:
            plt.imshow(adversarial.squeeze())

        plt.show()
        break

Namespace(adjoint=False, batch_size=128, continuing=False, data_aug=True, debug=False, downsampling_method='res', gpu=0, lr=0.1, nepochs=160, network='odenet', save='./experiment1', test_batch_size=1000, tol=0.001)
Only testing the top-10 classes
/Users/limuyang/Nustore Files/First Half of Junior Year/John/torchdiffeq/fooling/ode_fooling.py
import argparse
import logging
import os

import foolbox
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

DOWNLOAD_MNIST = False
use_gray = False

parser = argparse.ArgumentParser()
parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')
parser.add_argument('--tol', type=float, default=1e-3)
parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])
parser.add_argument('--downsampling-method', type=str, default='res', choices=['conv', 'res'])
parser.add_argument('--nepochs', type=int, default=160)
parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])
parser.add_argument('--lr', type=float, default=0.1)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--continuing', type=eval, default=False, choices=[True, False])
parser.add_argument('--save', type=str, default='./experiment1')
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint


def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)


def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


def norm(dim):
    return nn.GroupNorm(min(32, dim), dim)


def my_show_transform(x, use_gray):
    x = (x + 1.0) / 2.0
    """Imshow for Tensor."""
    x = np.clip(x, 0, 1)
    if use_gray:
        plt.imshow(x, cmap='gray')
    else:
        plt.imshow(x)
    return x


class ResBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(ResBlock, self).__init__()
        self.norm1 = norm(inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.norm2 = norm(planes)
        self.conv2 = conv3x3(planes, planes)

    def forward(self, x):
        shortcut = x

        out = self.relu(self.norm1(x))

        if self.downsample is not None:
            shortcut = self.downsample(out)

        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)

        return out + shortcut


class ODEfunc(nn.Module):

    def __init__(self, dim):
        super(ODEfunc, self).__init__()
        self.norm1 = norm(dim)
        self.relu = nn.ReLU(inplace=True)
        self.conv1 = conv3x3(dim, dim)
        self.norm2 = norm(dim)
        self.conv2 = conv3x3(dim, dim)
        self.norm3 = norm(dim)
        self.nfe = 0

    def forward(self, t, x):
        self.nfe += 1
        out = self.norm1(x)
        out = self.relu(out)
        out = self.conv1(out)
        out = self.norm2(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.norm3(out)
        return out


class ODEBlock(nn.Module):

    def __init__(self, odefunc):
        super(ODEBlock, self).__init__()
        self.odefunc = odefunc
        self.integration_time = torch.tensor([0, 1]).float()

    def forward(self, x):
        self.integration_time = self.integration_time.type_as(x)
        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)
        return out[1]

    @property
    def nfe(self):
        return self.odefunc.nfe

    @nfe.setter
    def nfe(self, value):
        self.odefunc.nfe = value


class Flatten(nn.Module):

    def __init__(self):
        super(Flatten, self).__init__()

    def forward(self, x):
        shape = torch.prod(torch.tensor(x.shape[1:])).item()
        return x.view(-1, shape)


class RunningAverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self, momentum=0.99):
        self.momentum = momentum
        self.reset()

    def reset(self):
        self.val = None
        self.avg = 0

    def update(self, val):
        if self.val is None:
            self.avg = val
        else:
            self.avg = self.avg * self.momentum + val * (1 - self.momentum)
        self.val = val


def inf_generator(iterable):
    """Allows training with DataLoaders in a single infinite loop:
        for i, (x, y) in enumerate(inf_generator(train_loader)):
    """
    iterator = iterable.__iter__()
    while True:
        try:
            yield iterator.__next__()
        except StopIteration:
            iterator = iterable.__iter__()


def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):
    initial_learning_rate = args.lr * batch_size / batch_denom

    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]
    vals = [initial_learning_rate * decay for decay in decay_rates]

    def learning_rate_fn(itr):
        lt = [itr < b for b in boundaries] + [True]
        i = np.argmax(lt)
        return vals[i]

    return learning_rate_fn


def one_hot(x, K):
    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)


def accuracy(model, dataset_loader):
    total_correct = 0
    for x, y in dataset_loader:
        x = x.to(device)
        y = one_hot(np.array(y.numpy()), 10)

        target_class = np.argmax(y, axis=1)
        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)
        total_correct += np.sum(predicted_class == target_class)
    return total_correct / len(dataset_loader.dataset)


def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def makedirs(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):
    logger = logging.getLogger()
    if debug:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logger.setLevel(level)
    if saving:
        info_file_handler = logging.FileHandler(logpath, mode="a")
        info_file_handler.setLevel(level)
        logger.addHandler(info_file_handler)
    if displaying:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        logger.addHandler(console_handler)
    logger.info(filepath)
    with open(filepath, "r") as f:
        logger.info(f.read())

    for f in package_files:
        logger.info(f)
        with open(f, "r") as package_f:
            logger.info(package_f.read())

    return logger


if __name__ == '__main__':

    makedirs(args.save)
    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)

    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')

    is_odenet = args.network == 'odenet'

    if args.downsampling_method == 'conv':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
        ]
    elif args.downsampling_method == 'res':
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
        ]

    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]
    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]

    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)

    # pay attention to this!! 
    SET_CONTINUE = True
    if args.continuing or SET_CONTINUE:
        model.load_state_dict(torch.load('model.pth', map_location='cpu')['state_dict'])

    mean = np.array([0.5])
    std = np.array([0.5])

    fmodel = foolbox.models.PyTorchModel(
        model, bounds=(-1, 1), num_classes=10, preprocessing=(mean, std))

    # get source image and label
    my_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])

    test_data = torchvision.datasets.MNIST(
        root='./mnist',
        train=False,
        download=DOWNLOAD_MNIST,
        transform=my_transform
    )

    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)

    for batch_idx, (data, target) in enumerate(test_loader):
        label = target.data.numpy()[0]
        print('label', label)
        image = data.squeeze(0).cpu().numpy()
        plt.subplot(1, 2, 1)
        my_show_transform(image.squeeze(), use_gray)
        predict = np.argmax(fmodel.predictions(image))
        print('predicted class', predict)

        method_name = 'DeepFoolL2Attack'
        save_path = os.path.join(r'log/result_pic', method_name)
        makedirs(save_path)

        attack = foolbox.attacks.DeepFoolL2Attack()  # (fmodel)

        criterion = foolbox.criteria.Misclassification()
        adversarial = foolbox.Adversarial(fmodel, criterion, image, np.array(label, dtype=np.int64),
                                          distance=foolbox.distances.MSE)
        attack(adversarial)
        adversarial = adversarial.image

        adversarial_predict = np.argmax(fmodel.predictions(adversarial))
        print('adversarial class', adversarial_predict)
        plt.subplot(1, 2, 2)

        if use_gray:
            plt.imshow(adversarial.squeeze(), cmap='gray')
        else:
            plt.imshow(adversarial.squeeze())

        plt.show()
        break

Namespace(adjoint=False, batch_size=128, continuing=False, data_aug=True, debug=False, downsampling_method='res', gpu=0, lr=0.1, nepochs=160, network='odenet', save='./experiment1', test_batch_size=1000, tol=0.001)
Only testing the top-10 classes
